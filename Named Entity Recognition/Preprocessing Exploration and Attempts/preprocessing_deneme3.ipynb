{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH_JSON = \"./NLP-Teknofest24/NLPJSON/\"\n",
    "DATA_PATH_TXT = \"./NLP-Teknofest24/NLPTXT-1028 Etiketlenen Raporlar/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "d_list = list()\n",
    "for i in range(1,5):\n",
    "    with open(DATA_PATH_JSON+str(i)+\"/all.jsonl\",'r', encoding=\"utf-8\") as f:\n",
    "        for a in f.readlines():\n",
    "            d_list.append(json.loads(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = pd.DataFrame(d_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = meta_data.drop(\"Comments\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = meta_data.sort_values(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>34</td>\n",
       "      <td>BİLATERAL MAMOGRAFİ İNCELEMESİ\\nMeme parankimi...</td>\n",
       "      <td>[[31, 45, ANAT], [46, 59, OBS-PRESENT], [75, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>35</td>\n",
       "      <td>BİLATERAL MAMOGRAFİ İNCELEMESİ\\nHer iki meme p...</td>\n",
       "      <td>[[31, 43, ANAT], [44, 54, ANAT], [58, 76, OBS-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>36</td>\n",
       "      <td>BİLATERAL MAMOGRAFİ İNCELEMESİ\\nMemeler dağını...</td>\n",
       "      <td>[[31, 38, ANAT], [39, 46, ANAT], [47, 79, OBS-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>37</td>\n",
       "      <td>BİLATERAL MAMOGRAFİ İNCELEMESİ\\nMemeler ACR Ti...</td>\n",
       "      <td>[[31, 38, ANAT], [39, 48, OBS-PRESENT], [50, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>38</td>\n",
       "      <td>BİLATERAL MAMOGRAFİ İNCELEMESİ\\nHer iki meme t...</td>\n",
       "      <td>[[31, 43, ANAT], [45, 62, OBS-PRESENT], [63, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>2078</td>\n",
       "      <td>UNİLATERAL MAMOGRAFİ İNCELEMESİ\\nSol meme para...</td>\n",
       "      <td>[[32, 40, ANAT], [41, 58, ANAT], [58, 89, OBS-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>2079</td>\n",
       "      <td>UNİLATERAL MAMOGRAFİ İNCELEMESİ\\nSol meme cilt...</td>\n",
       "      <td>[[32, 40, ANAT], [40, 55, ANAT], [56, 65, OBS-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>2080</td>\n",
       "      <td>UNİLATERAL MAMOGRAFİ RAPORU\\nSol meme dokusu t...</td>\n",
       "      <td>[[28, 44, ANAT], [44, 49, OBS-PRESENT], [49, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>2081</td>\n",
       "      <td>UNİLATERAL MAMOGRAFİ İNCELEMESİ:\\nSağ meme pat...</td>\n",
       "      <td>[[33, 49, ANAT], [50, 63, OBS-PRESENT], [64, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>2082</td>\n",
       "      <td>UNİLATERAL MAMOGRAFİ İNCELEMESİ\\nSol meme cilt...</td>\n",
       "      <td>[[32, 39, ANAT], [40, 55, ANAT], [56, 65, OBS-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1028 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text  \\\n",
       "771    34  BİLATERAL MAMOGRAFİ İNCELEMESİ\\nMeme parankimi...   \n",
       "772    35  BİLATERAL MAMOGRAFİ İNCELEMESİ\\nHer iki meme p...   \n",
       "773    36  BİLATERAL MAMOGRAFİ İNCELEMESİ\\nMemeler dağını...   \n",
       "774    37  BİLATERAL MAMOGRAFİ İNCELEMESİ\\nMemeler ACR Ti...   \n",
       "775    38  BİLATERAL MAMOGRAFİ İNCELEMESİ\\nHer iki meme t...   \n",
       "..    ...                                                ...   \n",
       "252  2078  UNİLATERAL MAMOGRAFİ İNCELEMESİ\\nSol meme para...   \n",
       "253  2079  UNİLATERAL MAMOGRAFİ İNCELEMESİ\\nSol meme cilt...   \n",
       "254  2080  UNİLATERAL MAMOGRAFİ RAPORU\\nSol meme dokusu t...   \n",
       "255  2081  UNİLATERAL MAMOGRAFİ İNCELEMESİ:\\nSağ meme pat...   \n",
       "256  2082  UNİLATERAL MAMOGRAFİ İNCELEMESİ\\nSol meme cilt...   \n",
       "\n",
       "                                                 label  \n",
       "771  [[31, 45, ANAT], [46, 59, OBS-PRESENT], [75, 8...  \n",
       "772  [[31, 43, ANAT], [44, 54, ANAT], [58, 76, OBS-...  \n",
       "773  [[31, 38, ANAT], [39, 46, ANAT], [47, 79, OBS-...  \n",
       "774  [[31, 38, ANAT], [39, 48, OBS-PRESENT], [50, 7...  \n",
       "775  [[31, 43, ANAT], [45, 62, OBS-PRESENT], [63, 7...  \n",
       "..                                                 ...  \n",
       "252  [[32, 40, ANAT], [41, 58, ANAT], [58, 89, OBS-...  \n",
       "253  [[32, 40, ANAT], [40, 55, ANAT], [56, 65, OBS-...  \n",
       "254  [[28, 44, ANAT], [44, 49, OBS-PRESENT], [49, 7...  \n",
       "255  [[33, 49, ANAT], [50, 63, OBS-PRESENT], [64, 7...  \n",
       "256  [[32, 39, ANAT], [40, 55, ANAT], [56, 65, OBS-...  \n",
       "\n",
       "[1028 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = meta_data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                      34\n",
       "text     BİLATERAL MAMOGRAFİ İNCELEMESİ\\nMeme parankimi...\n",
       "label    [[31, 45, ANAT], [46, 59, OBS-PRESENT], [75, 8...\n",
       "Name: 771, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = meta_data.drop(\"id\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.reset_index().drop(\"index\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BİLATERAL MAMOGRAFİ İNCELEMESİ\\nMeme parankimi...</td>\n",
       "      <td>[[31, 45, ANAT], [46, 59, OBS-PRESENT], [75, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BİLATERAL MAMOGRAFİ İNCELEMESİ\\nHer iki meme p...</td>\n",
       "      <td>[[31, 43, ANAT], [44, 54, ANAT], [58, 76, OBS-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BİLATERAL MAMOGRAFİ İNCELEMESİ\\nMemeler dağını...</td>\n",
       "      <td>[[31, 38, ANAT], [39, 46, ANAT], [47, 79, OBS-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BİLATERAL MAMOGRAFİ İNCELEMESİ\\nMemeler ACR Ti...</td>\n",
       "      <td>[[31, 38, ANAT], [39, 48, OBS-PRESENT], [50, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BİLATERAL MAMOGRAFİ İNCELEMESİ\\nHer iki meme t...</td>\n",
       "      <td>[[31, 43, ANAT], [45, 62, OBS-PRESENT], [63, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>UNİLATERAL MAMOGRAFİ İNCELEMESİ\\nSol meme para...</td>\n",
       "      <td>[[32, 40, ANAT], [41, 58, ANAT], [58, 89, OBS-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>UNİLATERAL MAMOGRAFİ İNCELEMESİ\\nSol meme cilt...</td>\n",
       "      <td>[[32, 40, ANAT], [40, 55, ANAT], [56, 65, OBS-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>UNİLATERAL MAMOGRAFİ RAPORU\\nSol meme dokusu t...</td>\n",
       "      <td>[[28, 44, ANAT], [44, 49, OBS-PRESENT], [49, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>UNİLATERAL MAMOGRAFİ İNCELEMESİ:\\nSağ meme pat...</td>\n",
       "      <td>[[33, 49, ANAT], [50, 63, OBS-PRESENT], [64, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>UNİLATERAL MAMOGRAFİ İNCELEMESİ\\nSol meme cilt...</td>\n",
       "      <td>[[32, 39, ANAT], [40, 55, ANAT], [56, 65, OBS-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1028 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     BİLATERAL MAMOGRAFİ İNCELEMESİ\\nMeme parankimi...   \n",
       "1     BİLATERAL MAMOGRAFİ İNCELEMESİ\\nHer iki meme p...   \n",
       "2     BİLATERAL MAMOGRAFİ İNCELEMESİ\\nMemeler dağını...   \n",
       "3     BİLATERAL MAMOGRAFİ İNCELEMESİ\\nMemeler ACR Ti...   \n",
       "4     BİLATERAL MAMOGRAFİ İNCELEMESİ\\nHer iki meme t...   \n",
       "...                                                 ...   \n",
       "1023  UNİLATERAL MAMOGRAFİ İNCELEMESİ\\nSol meme para...   \n",
       "1024  UNİLATERAL MAMOGRAFİ İNCELEMESİ\\nSol meme cilt...   \n",
       "1025  UNİLATERAL MAMOGRAFİ RAPORU\\nSol meme dokusu t...   \n",
       "1026  UNİLATERAL MAMOGRAFİ İNCELEMESİ:\\nSağ meme pat...   \n",
       "1027  UNİLATERAL MAMOGRAFİ İNCELEMESİ\\nSol meme cilt...   \n",
       "\n",
       "                                                  label  \n",
       "0     [[31, 45, ANAT], [46, 59, OBS-PRESENT], [75, 8...  \n",
       "1     [[31, 43, ANAT], [44, 54, ANAT], [58, 76, OBS-...  \n",
       "2     [[31, 38, ANAT], [39, 46, ANAT], [47, 79, OBS-...  \n",
       "3     [[31, 38, ANAT], [39, 48, OBS-PRESENT], [50, 7...  \n",
       "4     [[31, 43, ANAT], [45, 62, OBS-PRESENT], [63, 7...  \n",
       "...                                                 ...  \n",
       "1023  [[32, 40, ANAT], [41, 58, ANAT], [58, 89, OBS-...  \n",
       "1024  [[32, 40, ANAT], [40, 55, ANAT], [56, 65, OBS-...  \n",
       "1025  [[28, 44, ANAT], [44, 49, OBS-PRESENT], [49, 7...  \n",
       "1026  [[33, 49, ANAT], [50, 63, OBS-PRESENT], [64, 7...  \n",
       "1027  [[32, 39, ANAT], [40, 55, ANAT], [56, 65, OBS-...  \n",
       "\n",
       "[1028 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split: Train+Validation and Test\n",
    "train_val_df, test_df = train_test_split(data_df, test_size=250, random_state=42)\n",
    "\n",
    "# Second split: Train and Validation\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>BİLATERAL MAMOGRAFİ İNCELEMESİ\\nBilateral meme...</td>\n",
       "      <td>[[31, 55, ANAT], [57, 77, OBS-PRESENT], [79, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>BİLATERAL MAMOGRAFİ İNCELEMESİ:\\nMeme paterni ...</td>\n",
       "      <td>[[32, 36, ANAT], [37, 44, ANAT], [45, 53, OBS-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>BİLATERAL MAMOGRAFİ İNCELEMESİ:\\nCilt ve cilta...</td>\n",
       "      <td>[[32, 48, ANAT], [49, 71, ANAT], [75, 91, ANAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>BİLATERAL MAMOGRAFİ İNCELEMESİ:\\nMemeler ACR T...</td>\n",
       "      <td>[[32, 39, ANAT], [40, 49, OBS-PRESENT], [50, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>BİLATERAL MAMOGRAFİ İNCELEMESİ\\nHer iki meme A...</td>\n",
       "      <td>[[31, 43, ANAT], [44, 53, OBS-PRESENT], [67, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>BİLATERAL MAMOGRAFİ İNCELEMESİ:\\nHer iki meme ...</td>\n",
       "      <td>[[32, 54, ANAT], [56, 69, ANAT], [70, 75, OBS-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>BİLATERAL MAMOGRAFİ İNCELEMESİ     \\nCilt-cilt...</td>\n",
       "      <td>[[36, 40, ANAT], [40, 51, ANAT], [51, 61, ANAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>BİLATERAL MAMOGRAFİ İNCELEMESİ\\nBilateral meme...</td>\n",
       "      <td>[[31, 45, ANAT], [46, 60, ANAT], [61, 70, OBS-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>BİLATERAL MAMOGRAFİ İNCELEMESİ     \\nCilt-cilt...</td>\n",
       "      <td>[[36, 61, ANAT], [62, 72, OBS-PRESENT], [73, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BİLATERAL MAMOGRAFİ İNCELEMESİ\\nHer iki memede...</td>\n",
       "      <td>[[31, 45, ANAT], [46, 53, OBS-ABSENT], [61, 79...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "919  BİLATERAL MAMOGRAFİ İNCELEMESİ\\nBilateral meme...   \n",
       "159  BİLATERAL MAMOGRAFİ İNCELEMESİ:\\nMeme paterni ...   \n",
       "607  BİLATERAL MAMOGRAFİ İNCELEMESİ:\\nCilt ve cilta...   \n",
       "674  BİLATERAL MAMOGRAFİ İNCELEMESİ:\\nMemeler ACR T...   \n",
       "749  BİLATERAL MAMOGRAFİ İNCELEMESİ\\nHer iki meme A...   \n",
       "..                                                 ...   \n",
       "897  BİLATERAL MAMOGRAFİ İNCELEMESİ:\\nHer iki meme ...   \n",
       "406  BİLATERAL MAMOGRAFİ İNCELEMESİ     \\nCilt-cilt...   \n",
       "51   BİLATERAL MAMOGRAFİ İNCELEMESİ\\nBilateral meme...   \n",
       "812  BİLATERAL MAMOGRAFİ İNCELEMESİ     \\nCilt-cilt...   \n",
       "34   BİLATERAL MAMOGRAFİ İNCELEMESİ\\nHer iki memede...   \n",
       "\n",
       "                                                 label  \n",
       "919  [[31, 55, ANAT], [57, 77, OBS-PRESENT], [79, 8...  \n",
       "159  [[32, 36, ANAT], [37, 44, ANAT], [45, 53, OBS-...  \n",
       "607  [[32, 48, ANAT], [49, 71, ANAT], [75, 91, ANAT...  \n",
       "674  [[32, 39, ANAT], [40, 49, OBS-PRESENT], [50, 5...  \n",
       "749  [[31, 43, ANAT], [44, 53, OBS-PRESENT], [67, 8...  \n",
       "..                                                 ...  \n",
       "897  [[32, 54, ANAT], [56, 69, ANAT], [70, 75, OBS-...  \n",
       "406  [[36, 40, ANAT], [40, 51, ANAT], [51, 61, ANAT...  \n",
       "51   [[31, 45, ANAT], [46, 60, ANAT], [61, 70, OBS-...  \n",
       "812  [[36, 61, ANAT], [62, 72, OBS-PRESENT], [73, 8...  \n",
       "34   [[31, 45, ANAT], [46, 53, OBS-ABSENT], [61, 79...  \n",
       "\n",
       "[250 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B-LABEL, I-LABEL şeklinde ayıran ve {'start': 31, 'end': 35, 'label': 'B-ANAT', 'token': 'Meme'} şeklinde bir dict'e çeviren metod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_label_IOB(text: str, label: list) -> list[dict]:\n",
    "    label_list_dict = []\n",
    "    start : int = label[0]\n",
    "    end : int = label[1]\n",
    "    catg : str = label[2]\n",
    "    part = text[start:end]\n",
    "    token_list = part.split(\" \")\n",
    "    first_token = token_list[0]\n",
    "    new_repr_begin = {\"start\": start, \"end\": start+len(first_token), \"label\": \"B-\"+catg, \"token\":first_token}\n",
    "    start += len(first_token) + 1\n",
    "    label_list_dict.append(new_repr_begin)\n",
    "    for i, t in enumerate(token_list):\n",
    "        if i == 0: continue\n",
    "        new_repr_inner = {\"start\": start, \"end\": start+len(t), \"label\": \"I-\"+catg, \"token\":t}\n",
    "        start += len(t) + 1\n",
    "        label_list_dict.append(new_repr_inner)\n",
    "    return label_list_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal LABEL şeklinde ayıran ve {'start': 31, 'end': 35, 'label': 'ANAT', 'token': 'Meme'} şeklinde bir dict'e çeviren metod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_redundant_spaces_regex(text: str) -> str:\n",
    "  return re.sub(r\"\\s+\", \" \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_label_normal(text: str, label: list) -> list[dict]:\n",
    "    label_list_dict = []\n",
    "    start : int = label[0]\n",
    "    end : int = label[1]\n",
    "    catg : str = label[2]\n",
    "    part = text[start:end]\n",
    "    token_list = remove_redundant_spaces_regex(part.strip()).split(\" \")\n",
    "    for i, t in enumerate(token_list):\n",
    "        new_repr_inner = {\"start\": start, \"end\": start+len(t), \"label\": catg, \"token\":t}\n",
    "        start += len(t) + 1\n",
    "        label_list_dict.append(new_repr_inner)\n",
    "    return label_list_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df_labels(df: pd.DataFrame):\n",
    "    for i in range(df.shape[0]):\n",
    "        text : str = df[\"text\"].iloc[i]\n",
    "        label_list : list = df[\"label\"].iloc[i]\n",
    "        transformed_labels : list = []\n",
    "        for label in label_list:\n",
    "            transformed_labels.extend(transform_label_normal(text,label))\n",
    "        df[\"label\"].iloc[i] = transformed_labels\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Her iki memeye yönelik Mammografi İncelemesi,\\...</td>\n",
       "      <td>[{'start': 46, 'end': 49, 'label': 'ANAT', 'to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>BİLATERAL MAMMOGRAFİ İNCELEMESİ\\nHer iki meme ...</td>\n",
       "      <td>[{'start': 32, 'end': 35, 'label': 'ANAT', 'to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>BİLATERAL MAMOGRAFİ İNCELEMESİ\\nHer iki meme A...</td>\n",
       "      <td>[{'start': 31, 'end': 34, 'label': 'ANAT', 'to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>BİLATERAL MAMOGRAFİ İNCELEMESİ:\\nMemeler ACR T...</td>\n",
       "      <td>[{'start': 32, 'end': 39, 'label': 'ANAT', 'to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>BİLATERAL MAMOGRAFİ İNCELEMESİ: \\nMemeler ACR ...</td>\n",
       "      <td>[{'start': 33, 'end': 40, 'label': 'ANAT', 'to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>BİLATERAL MAMOGRAFİ İNCELEMESİ:\\nHer iki medio...</td>\n",
       "      <td>[{'start': 130, 'end': 134, 'label': 'ANAT', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>BİLATERAL MAMOGRAFİ İNCELEMESİ:\\nHer iki meme ...</td>\n",
       "      <td>[{'start': 32, 'end': 35, 'label': 'ANAT', 'to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>BİLATERAL MAMOGRAFİ İNCELEMESİ\\nBilateral meme...</td>\n",
       "      <td>[{'start': 31, 'end': 40, 'label': 'ANAT', 'to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>BİLATERAL MAMOGRAFİ İNCELEMESİ\\nHer iki memede...</td>\n",
       "      <td>[{'start': 31, 'end': 34, 'label': 'ANAT', 'to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>BİLATERAL MAMOGRAFİ İNCELEMESİ:\\nHer iki meme ...</td>\n",
       "      <td>[{'start': 32, 'end': 35, 'label': 'ANAT', 'to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "236  Her iki memeye yönelik Mammografi İncelemesi,\\...   \n",
       "817  BİLATERAL MAMMOGRAFİ İNCELEMESİ\\nHer iki meme ...   \n",
       "124  BİLATERAL MAMOGRAFİ İNCELEMESİ\\nHer iki meme A...   \n",
       "131  BİLATERAL MAMOGRAFİ İNCELEMESİ:\\nMemeler ACR T...   \n",
       "512  BİLATERAL MAMOGRAFİ İNCELEMESİ: \\nMemeler ACR ...   \n",
       "..                                                 ...   \n",
       "679  BİLATERAL MAMOGRAFİ İNCELEMESİ:\\nHer iki medio...   \n",
       "363  BİLATERAL MAMOGRAFİ İNCELEMESİ:\\nHer iki meme ...   \n",
       "716  BİLATERAL MAMOGRAFİ İNCELEMESİ\\nBilateral meme...   \n",
       "279  BİLATERAL MAMOGRAFİ İNCELEMESİ\\nHer iki memede...   \n",
       "341  BİLATERAL MAMOGRAFİ İNCELEMESİ:\\nHer iki meme ...   \n",
       "\n",
       "                                                 label  \n",
       "236  [{'start': 46, 'end': 49, 'label': 'ANAT', 'to...  \n",
       "817  [{'start': 32, 'end': 35, 'label': 'ANAT', 'to...  \n",
       "124  [{'start': 31, 'end': 34, 'label': 'ANAT', 'to...  \n",
       "131  [{'start': 32, 'end': 39, 'label': 'ANAT', 'to...  \n",
       "512  [{'start': 33, 'end': 40, 'label': 'ANAT', 'to...  \n",
       "..                                                 ...  \n",
       "679  [{'start': 130, 'end': 134, 'label': 'ANAT', '...  \n",
       "363  [{'start': 32, 'end': 35, 'label': 'ANAT', 'to...  \n",
       "716  [{'start': 31, 'end': 40, 'label': 'ANAT', 'to...  \n",
       "279  [{'start': 31, 'end': 34, 'label': 'ANAT', 'to...  \n",
       "341  [{'start': 32, 'end': 35, 'label': 'ANAT', 'to...  \n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_copy = train_df.copy()\n",
    "train_df_copy = transform_df_labels(train_df_copy)\n",
    "test_df_copy = test_df.copy()\n",
    "test_df_copy = transform_df_labels(test_df_copy)\n",
    "val_df_copy = val_df.copy()\n",
    "val_df_copy = transform_df_labels(val_df_copy)\n",
    "train_df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    'O': 0,\n",
    "    'ANAT': 1,\n",
    "    'OBS-PRESENT': 2,\n",
    "    'OBS-UNCERTAIN':3,\n",
    "    'OBS-ABSENT': 4,\n",
    "    'IMPRESSION': 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataseti CoNLL2003 datasetinin formatına getirebilmek için wordleri ayıran basit bir tokenizer (NLTKWordTokenizer) kullandım. Bu tokenizer açıkçası çok da iyi değil gibi, \".\" hariç diğer noktalama işaretlerini farklı bir token olarak ayırıyor ama noktayı kelimeden ayırmıyor. Bu yüzden belki başka bir tokenizer kullanılabilir. Aşağıda da textlerin ner_taglarını oluşturdum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "t = nltk.tokenize.NLTKWordTokenizer()\n",
    "def transform_into_ner_tags(df: pd.DataFrame):\n",
    "    for i in range(df.shape[0]):\n",
    "        labels = df[\"label\"].iloc[i]\n",
    "        text = df[\"text\"].iloc[i]\n",
    "        count = 0\n",
    "        ner_tags = []\n",
    "        tokenized_text = remove_redundant_spaces_regex(text.replace(\"\\xa0\",\" \").replace(\"\\n\",\" \")).split()#t.tokenize(text)\n",
    "        #if i==0:print(tokenized_text)\n",
    "        for token in tokenized_text:\n",
    "            #if i==0:print(\"token: \",token, \"  label:\",labels[count][\"token\"], \"   count:\",count)\n",
    "            if count < len(labels) and (labels[count][\"token\"] in token or labels[count][\"token\"] == token or token in labels[count][\"token\"]):\n",
    "                ner_tags.append(label_mapping[labels[count][\"label\"]])\n",
    "                count+=1\n",
    "            else: ner_tags.append(label_mapping[\"O\"])\n",
    "        df.iloc[i] = tokenized_text, ner_tags\n",
    "    df.columns = [\"tokens\",\"ner_tags\"]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy = transform_into_ner_tags(train_df_copy)\n",
    "test_df_copy = transform_into_ner_tags(test_df_copy)\n",
    "val_df_copy = transform_into_ner_tags(val_df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d372d120df794088abfb027e58ece4a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7604878053c242ecbd36bc0306465513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ab3d5e397b4452888e05a243db5fc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "hf_dataset_train = Dataset.from_pandas(train_df_copy)\n",
    "hf_dataset_test = Dataset.from_pandas(test_df_copy)\n",
    "hf_dataset_val = Dataset.from_pandas(val_df_copy)\n",
    "\n",
    "def conll_format(example):\n",
    "    tokens = example[\"tokens\"]\n",
    "    ner_tags = example[\"ner_tags\"]\n",
    "    lines = []\n",
    "    for token, tag in zip(tokens, ner_tags):\n",
    "        lines.append(f\"{token} {tag}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "conll_data_train = hf_dataset_train.map(lambda x: {\"conll_format\": conll_format(x)}, remove_columns=[\"tokens\", \"ner_tags\"])\n",
    "conll_data_test = hf_dataset_test.map(lambda x: {\"conll_format\": conll_format(x)}, remove_columns=[\"tokens\", \"ner_tags\"])\n",
    "conll_data_val = hf_dataset_val.map(lambda x: {\"conll_format\": conll_format(x)}, remove_columns=[\"tokens\", \"ner_tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_test_list = [\"train\",\"val\",\"test\"]\n",
    "for i, d in enumerate([conll_data_train, conll_data_val, conll_data_test]):\n",
    "    with open(f\"ner_dataset_{train_val_test_list[i]}_impression_yok.conll\", \"w\") as f:\n",
    "        for entry in d[\"conll_format\"]:\n",
    "            f.write(entry + \"\\n\\n\")  # Add a blank line between sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict, Features, Sequence, Value, ClassLabel\n",
    "\n",
    "def read_conll(file_path):\n",
    "    tokens = []\n",
    "    ner_tags = []\n",
    "    sentences = []\n",
    "    sentence_tags = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if not line:  # Empty line means new sentence\n",
    "                if tokens:\n",
    "                    sentences.append(tokens)\n",
    "                    ner_tags.append(sentence_tags)\n",
    "                    tokens = []\n",
    "                    sentence_tags = []\n",
    "            else:\n",
    "                token, tag = line.split()\n",
    "                tokens.append(token)\n",
    "                sentence_tags.append(tag)\n",
    "        if tokens:  # Catch the last sentence if the file does not end with a newline\n",
    "            sentences.append(tokens)\n",
    "            ner_tags.append(sentence_tags)\n",
    "\n",
    "    return {\"tokens\": sentences, \"ner_tags\": ner_tags}\n",
    "\n",
    "# Read the data\n",
    "data_dict_train = read_conll(\"ner_dataset_train_impression_yok.conll\")\n",
    "data_dict_test = read_conll(\"ner_dataset_test_impression_yok.conll\")\n",
    "data_dict_val = read_conll(\"ner_dataset_val_impression_yok.conll\")\n",
    "\n",
    "# Define the dataset features\n",
    "features = Features({\n",
    "    \"tokens\": Sequence(Value(\"string\")),\n",
    "    \"ner_tags\": Sequence(ClassLabel(names=['O','ANAT','OBS-PRESENT','OBS-UNCERTAIN','OBS-ABSENT']))\n",
    "})\n",
    "\n",
    "# Create the dataset\n",
    "dataset_dict = DatasetDict({\"train\": Dataset.from_dict(data_dict_train, features=features), \n",
    "                            \"validation\":Dataset.from_dict(data_dict_val, features=features), \n",
    "                            \"test\":Dataset.from_dict(data_dict_test, features=features)})\n",
    "\n",
    "# Print a sample to check if it loaded correctly\n",
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae7064c16d1494091d37a12757bd75d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71269e74b154d8dbdeb18ea0abe5fd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae0bd41a2234560a41130d381819835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_dict.save_to_disk(\"ner_dataset_conll_format_impression_yok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "load_from_disk(\"ner_dataset_conll_format_impression_yok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_copy[\"ner_tags\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yusuf\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452a116069a24f1481ad73d4a1cbfd04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 1\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizerFast\n",
    "from datasets import Dataset\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    \"text\": [\"BİLATERAL MAMOGRAFİ\\xa0İNCELEMESİ\\nMeme paterni tip 'A''dir.\\nBilateral cilt, cilt altı ve nipple-areolar kompleksler doğaldır.\\nHer iki memede birkaç adet benign natürde kalsifikasyon izlendi. \\nBilateral  memede net demarke yer kaplayan oluşum ve malign kriterler taşıyan mikrokalsifikasyon kümesi izlenmedi.\\nBilateral aksiller bölgede patolojik boyut ve özellikte lenf nodu izlenmedi.\\nSONUÇ: BIRADS 2\"],\n",
    "    \"label\": [[[31, 43, 'ANAT'], [44, 56, 'OBS-PRESENT'], [57, 71, 'ANAT'], [73, 82, 'ANAT'], [86, 112, 'ANAT'], [113, 122, 'OBS-PRESENT'], [123, 137, 'ANAT'], [138, 149, 'OBS-PRESENT'], [150, 164, 'OBS-PRESENT'], [165, 178, 'OBS-PRESENT'], [189, 206, 'ANAT'], [207, 239, 'OBS-ABSENT'], [242, 266, 'OBS-ABSENT'], [267, 293, 'OBS-ABSENT'], [304, 330, 'ANAT'], [331, 359, 'OBS-ABSENT'], [360, 369, 'OBS-ABSENT'], [387, 396, 'IMPRESSION']]]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define label mapping\n",
    "label_mapping = {\n",
    "    'ANAT': 0,\n",
    "    'OBS-PRESENT': 1,\n",
    "    'OBS-ABSENT': 2,\n",
    "    'IMPRESSION': 3\n",
    "}\n",
    "\n",
    "# Convert labels to indices\n",
    "def convert_labels_to_indices(label_list):\n",
    "    return [[(start, end, label_mapping[label]) for start, end, label in entity_list] for entity_list in label_list]\n",
    "\n",
    "# Apply the conversion\n",
    "df['label'] = convert_labels_to_indices(df['label'])\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')\n",
    "\n",
    "# Function to tokenize and align labels\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"text\"], truncation=True, padding=True, return_offsets_mapping=True)\n",
    "    \n",
    "    new_labels = []\n",
    "    for i, (text, entities) in enumerate(zip(examples[\"text\"], examples[\"label\"])):\n",
    "        offset_mapping = tokenized_inputs[\"offset_mapping\"][i]\n",
    "        label_ids = [-100] * len(offset_mapping)\n",
    "        \n",
    "        for start, end, label in entities:\n",
    "            for idx, (token_start, token_end) in enumerate(offset_mapping):\n",
    "                if token_start is None or token_end is None:\n",
    "                    continue\n",
    "                if token_start >= start and token_end <= end:\n",
    "                    label_ids[idx] = label\n",
    "\n",
    "        new_labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Convert the DataFrame to a Hugging Face Dataset\n",
    "hf_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Tokenize and align labels\n",
    "tokenized_dataset = hf_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "tokenized_dataset = tokenized_dataset.remove_columns(\"offset_mapping\")\n",
    "# Print the tokenized dataset\n",
    "print(tokenized_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "(\"Could not convert 'ANAT' with type str: tried to convert to int64\", 'Conversion failed for column label with type object')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[126], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: tokenized_input[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: tokenized_input[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m: labels}\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Apply tokenization and alignment to the dataset\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m tokenized_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmap(tokenize_and_align_labels)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Print the tokenized dataset\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(tokenized_dataset)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\datasets\\arrow_dataset.py:870\u001b[0m, in \u001b[0;36mDataset.from_pandas\u001b[1;34m(cls, df, features, info, split, preserve_index)\u001b[0m\n\u001b[0;32m    868\u001b[0m     info \u001b[38;5;241m=\u001b[39m DatasetInfo()\n\u001b[0;32m    869\u001b[0m info\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;241m=\u001b[39m features\n\u001b[1;32m--> 870\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[43mInMemoryTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreserve_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreserve_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    875\u001b[0m     \u001b[38;5;66;03m# more expensive cast than InMemoryTable.from_pandas(..., schema=features.arrow_schema)\u001b[39;00m\n\u001b[0;32m    876\u001b[0m     \u001b[38;5;66;03m# needed to support the str to Audio conversion for instance\u001b[39;00m\n\u001b[0;32m    877\u001b[0m     table \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mcast(features\u001b[38;5;241m.\u001b[39marrow_schema)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\datasets\\table.py:720\u001b[0m, in \u001b[0;36mInMemoryTable.from_pandas\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pandas\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    666\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;124;03m    Convert pandas.DataFrame to an Arrow Table.\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[0;32m    719\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pyarrow\\table.pxi:4525\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pyarrow\\pandas_compat.py:611\u001b[0m, in \u001b[0;36mdataframe_to_arrays\u001b[1;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[0;32m    606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    607\u001b[0m             arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mcontiguous \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    608\u001b[0m             \u001b[38;5;28missubclass\u001b[39m(arr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, np\u001b[38;5;241m.\u001b[39minteger))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nthreads \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 611\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mconvert_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m              \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcolumns_to_convert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_fields\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    614\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pyarrow\\pandas_compat.py:611\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    607\u001b[0m             arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mcontiguous \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    608\u001b[0m             \u001b[38;5;28missubclass\u001b[39m(arr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, np\u001b[38;5;241m.\u001b[39minteger))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nthreads \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 611\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\u001b[43mconvert_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    612\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m c, f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(columns_to_convert, convert_fields)]\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    614\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pyarrow\\pandas_compat.py:598\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[1;34m(col, field)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[0;32m    594\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[0;32m    595\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    596\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    597\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n\u001b[1;32m--> 598\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m field_nullable \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39mnull_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    600\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mField \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m was non-nullable but pandas column \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    601\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhad \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m null values\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mstr\u001b[39m(field),\n\u001b[0;32m    602\u001b[0m                                                  result\u001b[38;5;241m.\u001b[39mnull_count))\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pyarrow\\pandas_compat.py:592\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[1;34m(col, field)\u001b[0m\n\u001b[0;32m    589\u001b[0m     type_ \u001b[38;5;241m=\u001b[39m field\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 592\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_pandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[0;32m    594\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[0;32m    595\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    596\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    597\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pyarrow\\array.pxi:345\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pyarrow\\array.pxi:85\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pyarrow\\error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowInvalid\u001b[0m: (\"Could not convert 'ANAT' with type str: tried to convert to int64\", 'Conversion failed for column label with type object')"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizerFast\n",
    "from datasets import Dataset\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    \"text\": [\"BİLATERAL MAMOGRAFİ İNCELEMESİ\\nMeme paterni tip 'A''dir.\\nBilateral cilt, cilt altı ve nipple-areolar kompleksler doğaldır.\\nHer iki memede birkaç adet benign natürde kalsifikasyon izlendi. \\nBilateral  memede net demarke yer kaplayan oluşum ve malign kriterler taşıyan mikrokalsifikasyon kümesi izlenmedi.\\nBilateral aksiller bölgede patolojik boyut ve özellikte lenf nodu izlenmedi.\\nSONUÇ: BIRADS 2\"],\n",
    "    \"label\": [[[31, 43, 'ANAT'], [44, 56, 'OBS-PRESENT'], [57, 71, 'ANAT'], [73, 82, 'ANAT'], [86, 112, 'ANAT'], [113, 122, 'OBS-PRESENT'], [123, 137, 'ANAT'], [138, 149, 'OBS-PRESENT'], [150, 164, 'OBS-PRESENT'], [165, 178, 'OBS-PRESENT'], [189, 206, 'ANAT'], [207, 239, 'OBS-ABSENT'], [242, 266, 'OBS-ABSENT'], [267, 293, 'OBS-ABSENT'], [304, 330, 'ANAT'], [331, 359, 'OBS-ABSENT'], [360, 369, 'OBS-ABSENT'], [387, 396, 'IMPRESSION']]]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')\n",
    "\n",
    "# Encode labels\n",
    "label_mapping = {'ANAT': 0, 'OBS-PRESENT': 1, 'OBS-ABSENT': 2, 'IMPRESSION': 3}\n",
    "\n",
    "# Tokenize text and align labels\n",
    "def tokenize_and_align_labels(example):\n",
    "    tokenized_input = tokenizer(example['text'], padding='max_length', truncation=True, return_offsets_mapping=True)\n",
    "    tokens = tokenizer.convert_ids_to_tokens(tokenized_input['input_ids'])\n",
    "    \n",
    "    labels = [0] * len(tokens)  # Initialize labels with zeros\n",
    "    for start, end, label in example['label'][0]:\n",
    "        for idx, (token_start, token_end) in enumerate(tokenized_input['offset_mapping']):\n",
    "            if token_start is None or token_end is None:\n",
    "                continue\n",
    "            if token_start >= start and token_end <= end:\n",
    "                labels[idx] = label_mapping[label]\n",
    "    return {'input_ids': tokenized_input['input_ids'], 'attention_mask': tokenized_input['attention_mask'], 'labels': labels}\n",
    "\n",
    "# Apply tokenization and alignment to the dataset\n",
    "tokenized_dataset = Dataset.from_pandas(df).map(tokenize_and_align_labels)\n",
    "\n",
    "# Print the tokenized dataset\n",
    "print(tokenized_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'BİL',\n",
       " '##AT',\n",
       " '##ER',\n",
       " '##AL',\n",
       " 'MA',\n",
       " '##M',\n",
       " '##OG',\n",
       " '##RAF',\n",
       " '##İ',\n",
       " 'İN',\n",
       " '##CEL',\n",
       " '##EM',\n",
       " '##ESİ',\n",
       " 'Meme',\n",
       " 'paran',\n",
       " '##kim',\n",
       " '##i',\n",
       " 'tip',\n",
       " 'A',\n",
       " 'pat',\n",
       " '##ern',\n",
       " 'ile',\n",
       " 'uyumlu',\n",
       " '##dur',\n",
       " '.',\n",
       " 'Sp',\n",
       " '##ik',\n",
       " '##üler',\n",
       " 'kitle',\n",
       " ',',\n",
       " 'yapısal',\n",
       " 'dist',\n",
       " '##ors',\n",
       " '##iyon',\n",
       " ',',\n",
       " 've',\n",
       " 'mali',\n",
       " '##gn',\n",
       " '##ite',\n",
       " 'şüphe',\n",
       " '##si',\n",
       " 'uyandıran',\n",
       " 'mikro',\n",
       " '##kal',\n",
       " '##si',\n",
       " '##fik',\n",
       " '##asyon',\n",
       " 'küme',\n",
       " '##si',\n",
       " 'izlenme',\n",
       " '##miştir',\n",
       " '.',\n",
       " 'Sol',\n",
       " 'meme',\n",
       " '##de',\n",
       " 'üst',\n",
       " 'dış',\n",
       " 'kadr',\n",
       " '##anda',\n",
       " 'birkaç',\n",
       " 'adet',\n",
       " 'makro',\n",
       " '##kal',\n",
       " '##si',\n",
       " '##fik',\n",
       " '##asyon',\n",
       " 'mevcuttur',\n",
       " '.',\n",
       " 'Bil',\n",
       " '##ater',\n",
       " '##al',\n",
       " 'aksi',\n",
       " '##ll',\n",
       " '##er',\n",
       " 'alanlarda',\n",
       " 'lenf',\n",
       " 'no',\n",
       " '##du',\n",
       " 'izlenme',\n",
       " '##miştir',\n",
       " '.',\n",
       " 'SONU',\n",
       " '##Ç',\n",
       " ':',\n",
       " 'BI',\n",
       " '##RA',\n",
       " '##DS',\n",
       " '2',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input = tokenizer(example_text[\"text\"])\n",
    "tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                      34\n",
       "text     BİLATERAL MAMOGRAFİ İNCELEMESİ\\nMeme parankimi...\n",
       "label    [[31, 45, ANAT], [46, 59, OBS-PRESENT], [75, 8...\n",
       "Name: 771, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BİLATERAL',\n",
       " 'MAMOGRAFİ',\n",
       " 'İNCELEMESİ',\n",
       " 'Meme',\n",
       " 'paterni',\n",
       " 'tip',\n",
       " \"'\",\n",
       " 'A',\n",
       " \"''\",\n",
       " 'dir.',\n",
       " 'Bilateral',\n",
       " 'cilt',\n",
       " ',',\n",
       " 'cilt',\n",
       " 'altı',\n",
       " 've',\n",
       " 'nipple-areolar',\n",
       " 'kompleksler',\n",
       " 'doğaldır.',\n",
       " 'Her',\n",
       " 'iki',\n",
       " 'memede',\n",
       " 'birkaç',\n",
       " 'adet',\n",
       " 'benign',\n",
       " 'natürde',\n",
       " 'kalsifikasyon',\n",
       " 'izlendi.',\n",
       " 'Bilateral',\n",
       " 'memede',\n",
       " 'net',\n",
       " 'demarke',\n",
       " 'yer',\n",
       " 'kaplayan',\n",
       " 'oluşum',\n",
       " 've',\n",
       " 'malign',\n",
       " 'kriterler',\n",
       " 'taşıyan',\n",
       " 'mikrokalsifikasyon',\n",
       " 'kümesi',\n",
       " 'izlenmedi.',\n",
       " 'Bilateral',\n",
       " 'aksiller',\n",
       " 'bölgede',\n",
       " 'patolojik',\n",
       " 'boyut',\n",
       " 've',\n",
       " 'özellikte',\n",
       " 'lenf',\n",
       " 'nodu',\n",
       " 'izlenmedi.',\n",
       " 'SONUÇ',\n",
       " ':',\n",
       " 'BIRADS',\n",
       " '2']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "t = nltk.tokenize.NLTKWordTokenizer()\n",
    "t.tokenize(train_df[\"text\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BİLATERAL',\n",
       " 'MAMOGRAFİ',\n",
       " 'İNCELEMESİ',\n",
       " 'Meme',\n",
       " 'paterni',\n",
       " 'tip',\n",
       " \"'A''dir.\",\n",
       " 'Bilateral',\n",
       " 'cilt,',\n",
       " 'cilt',\n",
       " 'altı',\n",
       " 've',\n",
       " 'nipple-areolar',\n",
       " 'kompleksler',\n",
       " 'doğaldır.',\n",
       " 'Her',\n",
       " 'iki',\n",
       " 'memede',\n",
       " 'birkaç',\n",
       " 'adet',\n",
       " 'benign',\n",
       " 'natürde',\n",
       " 'kalsifikasyon',\n",
       " 'izlendi.',\n",
       " '',\n",
       " 'Bilateral',\n",
       " '',\n",
       " 'memede',\n",
       " 'net',\n",
       " 'demarke',\n",
       " 'yer',\n",
       " 'kaplayan',\n",
       " 'oluşum',\n",
       " 've',\n",
       " 'malign',\n",
       " 'kriterler',\n",
       " 'taşıyan',\n",
       " 'mikrokalsifikasyon',\n",
       " 'kümesi',\n",
       " 'izlenmedi.',\n",
       " 'Bilateral',\n",
       " 'aksiller',\n",
       " 'bölgede',\n",
       " 'patolojik',\n",
       " 'boyut',\n",
       " 've',\n",
       " 'özellikte',\n",
       " 'lenf',\n",
       " 'nodu',\n",
       " 'izlenmedi.',\n",
       " 'SONUÇ:',\n",
       " 'BIRADS',\n",
       " '2']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"text\"].iloc[0].replace(\"\\xa0\",\" \").replace(\"\\n\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[31, 43, 'ANAT'],\n",
       " [44, 56, 'OBS-PRESENT'],\n",
       " [57, 71, 'ANAT'],\n",
       " [73, 82, 'ANAT'],\n",
       " [86, 112, 'ANAT'],\n",
       " [113, 122, 'OBS-PRESENT'],\n",
       " [123, 137, 'ANAT'],\n",
       " [138, 149, 'OBS-PRESENT'],\n",
       " [150, 164, 'OBS-PRESENT'],\n",
       " [165, 178, 'OBS-PRESENT'],\n",
       " [189, 206, 'ANAT'],\n",
       " [207, 239, 'OBS-ABSENT'],\n",
       " [242, 266, 'OBS-ABSENT'],\n",
       " [267, 293, 'OBS-ABSENT'],\n",
       " [304, 330, 'ANAT'],\n",
       " [331, 359, 'OBS-ABSENT'],\n",
       " [360, 369, 'OBS-ABSENT'],\n",
       " [387, 396, 'IMPRESSION']]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"label\"].iloc[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
