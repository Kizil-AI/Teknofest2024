{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_rdDxOAz0bP",
        "outputId": "0a532c40-4c33-4132-8bbb-bcb10b0b94db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/547.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m327.7/547.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting deap\n",
            "  Downloading deap-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Collecting requests>=2.32.2 (from datasets)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.3.0+cu121)\n",
            "Collecting accelerate>=0.21.0 (from transformers[torch])\n",
            "  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.6.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->transformers[torch])\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->transformers[torch])\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=ae437a2a52aef16fe688797eba24a4dcf8df64e02eb4a9c193dca065f0de3c91\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: xxhash, requests, pyarrow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, deap, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, seqeval, nvidia-cusolver-cu12, datasets, accelerate\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.31.0 datasets-2.20.0 deap-1.4.1 dill-0.3.8 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pyarrow-16.1.0 requests-2.32.3 seqeval-1.2.2 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers[torch] seqeval deap"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_from_disk\n",
        "dataset = load_from_disk(\"drive/MyDrive/ner_dataset_conll_format_impression_yok\")"
      ],
      "metadata": {
        "id": "TWSpfKjE0ETb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model_names = [\"sezinarseven/turkish-medical-field-detection-8\",\"dbmdz/convbert-base-turkish-cased\",\"busecarik/berturk-sunlp-ner-turkish\",\"savasy/bert-base-turkish-ner-cased\",\"dbmdz/convbert-base-turkish-mc4-cased\",\"dbmdz/bert-base-turkish-cased\",\"google-bert/bert-base-multilingual-cased\",\"dbmdz/distilbert-base-turkish-cased\",\"Buseak/penn_berturk_0203_v5\",\"Buseak/model_from_berturk_Feb_5_TrainTestSplit\",\"alierenak/berturk_cased_ner\"]\n",
        "model_names = [\"google-t5/t5-large\",\"google-t5/t5-base\"]\n",
        "MODEL_PATH = \"/content/drive/MyDrive/ner_model_\""
      ],
      "metadata": {
        "id": "-bl335yJ0HDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
        "tokenizers = [AutoTokenizer.from_pretrained(model_name) for model_name in model_names]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUMU9x9k0PK3",
        "outputId": "7a69f327-277d-4114-dfb9-e9a20ed52165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_align_labels(examples, label_all_tokens=True):\n",
        "    tokenized_inputs = cur_tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])\n",
        "            else:\n",
        "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "tokenized_datasets_list = []\n",
        "for i in range(len(tokenizers)):\n",
        "  cur_tokenizer = tokenizers[i]\n",
        "  a = dataset.map(tokenize_and_align_labels, batched=True)\n",
        "  tokenized_datasets_list.append(a)\n"
      ],
      "metadata": {
        "id": "deisb7510T4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "metric = datasets.load_metric(\"seqeval\",trust_remote_code=True)\n",
        "label_list = dataset[\"train\"].features[\"ner_tags\"].feature.names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFNx05_A0V0S",
        "outputId": "9e6004a7-0a26-4fe1-aa73-94fde2e39e2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-169ace8f2e25>:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = datasets.load_metric(\"seqeval\",trust_remote_code=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def compute_metrics(eval_preds):\n",
        "    \"\"\"\n",
        "    Function to compute the evaluation metrics for Named Entity Recognition (NER) tasks.\n",
        "    The function computes precision, recall, F1 score and accuracy.\n",
        "\n",
        "    Parameters:\n",
        "    eval_preds (tuple): A tuple containing the predicted logits and the true labels.\n",
        "\n",
        "    Returns:\n",
        "    A dictionary containing the precision, recall, F1 score and accuracy.\n",
        "    \"\"\"\n",
        "    pred_logits, labels = eval_preds\n",
        "\n",
        "    pred_logits = np.argmax(pred_logits, axis=2)\n",
        "    # the logits and the probabilities are in the same order,\n",
        "    # so we don‚Äôt need to apply the softmax\n",
        "\n",
        "    # We remove all the values where the label is -100\n",
        "    predictions = [\n",
        "        [label_list[eval_preds] for (eval_preds, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(pred_logits, labels)\n",
        "    ]\n",
        "\n",
        "    true_labels = [\n",
        "      [label_list[l] for (eval_preds, l) in zip(prediction, label) if l != -100]\n",
        "       for prediction, label in zip(pred_logits, labels)\n",
        "   ]\n",
        "    results = metric.compute(predictions=predictions, references=true_labels)\n",
        "    return {\n",
        "   \"precision\": results[\"overall_precision\"],\n",
        "   \"recall\": results[\"overall_recall\"],\n",
        "   \"f1\": results[\"overall_f1\"],\n",
        "  \"accuracy\": results[\"overall_accuracy\"],\n",
        "    }"
      ],
      "metadata": {
        "id": "AQSIoP230YXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix,classification_report,f1_score,precision_score,recall_score,accuracy_score\n",
        "def compute_metrics2(eval_preds):\n",
        "    \"\"\"\n",
        "    Function to compute the evaluation metrics for Named Entity Recognition (NER) tasks.\n",
        "    The function computes precision, recall, F1 score and accuracy.\n",
        "\n",
        "    Parameters:\n",
        "    eval_preds (tuple): A tuple containing the predicted logits and the true labels.\n",
        "\n",
        "    Returns:\n",
        "    A dictionary containing the precision, recall, F1 score and accuracy.\n",
        "    \"\"\"\n",
        "    pred_logits, labels = eval_preds\n",
        "\n",
        "    pred_logits = np.argmax(pred_logits, axis=2)\n",
        "    # the logits and the probabilities are in the same order,\n",
        "    # so we don‚Äôt need to apply the softmax\n",
        "\n",
        "    # We remove all the values where the label is -100\n",
        "    predictions = [\n",
        "        [label_list[eval_preds] for (eval_preds, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(pred_logits, labels)\n",
        "    ]\n",
        "\n",
        "    true_labels = [\n",
        "      [label_list[l] for (eval_preds, l) in zip(prediction, label) if l != -100]\n",
        "       for prediction, label in zip(pred_logits, labels)\n",
        "   ]\n",
        "\n",
        "    true_labels_flat = [label for sublist in true_labels for label in sublist]\n",
        "    pred_labels_flat = [label for sublist in predictions for label in sublist]\n",
        "\n",
        "    f1 = f1_score(true_labels_flat, pred_labels_flat, average='weighted')\n",
        "    precision = precision_score(true_labels_flat, pred_labels_flat, average='weighted')\n",
        "    recall = recall_score(true_labels_flat, pred_labels_flat, average='weighted')\n",
        "    accuracy = accuracy_score(true_labels_flat, pred_labels_flat)\n",
        "\n",
        "    return {\n",
        "   \"precision\": precision,\n",
        "   \"recall\": recall,\n",
        "   \"f1\": f1,\n",
        "  \"accuracy\": accuracy,\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "id": "Y9W7osTRYfVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForTokenClassification,Trainer\n",
        "model_loaded_list = [AutoModelForTokenClassification.from_pretrained(MODEL_PATH + model_name.replace(\"/\",\"_\")+\"_impression_yok\") for model_name in model_names]\n",
        "trainer_list = [Trainer(\n",
        "    model=model_loaded_list[i],\n",
        "    data_collator=DataCollatorForTokenClassification(tokenizers[i]),\n",
        "    tokenizer=tokenizers[i],\n",
        "    compute_metrics=compute_metrics2,\n",
        ") for i in range(len(model_loaded_list))]"
      ],
      "metadata": {
        "id": "2ekDux3RYkI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_list[1].evaluate(tokenized_datasets_list[1][\"test\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "KbizG9I31UMf",
        "outputId": "482f4cbc-c7d1-42e3-e574-33d33f1ea30d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [32/32 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 1.3291279077529907,\n",
              " 'eval_precision': 0.8880964309996527,\n",
              " 'eval_recall': 0.8878481804216909,\n",
              " 'eval_f1': 0.8872760039385544,\n",
              " 'eval_accuracy': 0.8878481804216909,\n",
              " 'eval_runtime': 5.2172,\n",
              " 'eval_samples_per_second': 47.918,\n",
              " 'eval_steps_per_second': 6.134}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_list = [trainer_list[i].predict(tokenized_datasets_list[i][\"test\"]).predictions for i in range(len(trainer_list))]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "rf6jL9EV0dMw",
        "outputId": "a1107979-6abc-4712-d0d2-93ecf12e1700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coef_list = [0.46,0.54]\n",
        "combined_test_preds_proba = prediction_list[0]*coef_list[0] + prediction_list[1]*coef_list[1]\n",
        "test_labels = tokenized_datasets_list[1][\"test\"][\"labels\"]\n",
        "print(compute_metrics2((combined_test_preds_proba,test_labels)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdIbyyb5EIOU",
        "outputId": "7c18955d-e35d-4cc7-cd02-b660c27dd725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'precision': 0.8913930899320432, 'recall': 0.8909748372099346, 'f1': 0.8903341897480656, 'accuracy': 0.8909748372099346}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('hardcoded_dict_tokenized_5.pkl', 'rb') as f:\n",
        "    hardcoded_dict = pickle.load(f)\n",
        "print(hardcoded_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IadkQe50D6E4",
        "outputId": "6aefab7f-8240-431a-fe7b-f845e9c6809b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{7419: [0.2915601023017903, 0.020460358056265986, 0.33248081841432225, 0.0, 0.3554987212276215], 6570: [0.23655913978494625, 0.0, 0.7634408602150538, 0.0, 0.0], 2067: [0.11371237458193979, 0.0, 0.8862876254180602, 0.0, 0.0], 18: [0.767349260523322, 0.00881683731513083, 0.21302616609783845, 0.004835039817974972, 0.005972696245733789], 7085: [0.15613382899628253, 0.0, 0.7695167286245354, 0.0, 0.07434944237918216], 4082: [0.17079889807162535, 0.0, 0.5454545454545454, 0.0027548209366391185, 0.2809917355371901], 2433: [0.2, 0.0, 0.6, 0.2, 0.0], 20471: [0.058823529411764705, 0.0, 0.9411764705882353, 0.0, 0.0], 2235: [0.13871951219512196, 0.0, 0.5945121951219512, 0.0, 0.26676829268292684], 2462: [0.15738284703801944, 0.01856763925729443, 0.47745358090185674, 0.0, 0.34659593280282935], 8038: [0.14563106796116504, 0.000970873786407767, 0.5174757281553398, 0.0, 0.3359223300970874], 19943: [0.13675213675213677, 0.002849002849002849, 0.8319088319088319, 0.0, 0.02849002849002849], 6915: [0.9505119453924915, 0.008532423208191127, 0.034129692832764506, 0.0, 0.006825938566552901], 2016: [0.9604904632152589, 0.006811989100817439, 0.02452316076294278, 0.0, 0.008174386920980926], 21712: [0.15841584158415842, 0.0033003300330033004, 0.1782178217821782, 0.0, 0.6600660066006601], 23044: [0.16326530612244897, 0.0, 0.1598639455782313, 0.0, 0.6768707482993197], 2722: [0.16326530612244897, 0.0, 0.1598639455782313, 0.0, 0.6768707482993197], 1987: [0.0, 0.0, 1.0, 0.0, 0.0], 9230: [0.05263157894736842, 0.0, 0.8947368421052632, 0.05263157894736842, 0.0], 4028: [0.0625, 0.0, 0.9375, 0.0, 0.0], 4379: [0.25, 0.0, 0.75, 0.0, 0.0], 92: [0.1375, 0.0, 0.8625, 0.0, 0.0], 3949: [0.0, 0.0, 1.0, 0.0, 0.0], 8215: [0.14285714285714285, 0.029304029304029304, 0.8278388278388278, 0.0, 0.0], 31820: [0.0963855421686747, 0.0, 0.9036144578313253, 0.0, 0.0], 6113: [0.0625, 0.0, 0.9375, 0.0, 0.0], 2410: [0.08571428571428572, 0.05714285714285714, 0.8571428571428571, 0.0, 0.0], 8963: [0.0625, 0.0, 0.9375, 0.0, 0.0], 1972: [0.15894039735099338, 0.5916114790286976, 0.24944812362030905, 0.0, 0.0], 1988: [0.17530487804878048, 0.5213414634146342, 0.18521341463414634, 0.0, 0.11814024390243902], 7442: [0.16379310344827586, 0.0, 0.1206896551724138, 0.008620689655172414, 0.7068965517241379], 8829: [0.17771084337349397, 0.0, 0.4367469879518072, 0.006024096385542169, 0.3795180722891566], 14325: [0.128060263653484, 0.007532956685499058, 0.3389830508474576, 0.0018832391713747645, 0.5235404896421846], 2174: [0.15384615384615385, 0.01282051282051282, 0.5897435897435898, 0.003205128205128205, 0.2403846153846154], 4777: [0.045774647887323945, 0.0, 0.954225352112676, 0.0, 0.0], 2350: [0.10975609756097561, 0.024390243902439025, 0.8658536585365854, 0.0, 0.0], 1022: [0.17796610169491525, 0.059322033898305086, 0.7627118644067796, 0.0, 0.0], 11920: [0.08333333333333333, 0.09259259259259259, 0.8240740740740741, 0.0, 0.0], 2265: [0.09401709401709402, 0.08547008547008547, 0.8205128205128205, 0.0, 0.0], 14936: [0.09166666666666666, 0.08333333333333333, 0.825, 0.0, 0.0], 3773: [0.177734375, 0.1123046875, 0.3115234375, 0.0, 0.3984375], 4292: [0.22095238095238096, 0.21523809523809523, 0.5638095238095238, 0.0, 0.0], 3216: [0.16568047337278108, 0.0, 0.8284023668639053, 0.005917159763313609, 0.0], 7117: [0.1553672316384181, 0.002824858757062147, 0.3672316384180791, 0.0, 0.4745762711864407], 2510: [0.14864864864864866, 0.0, 0.2922297297297297, 0.0, 0.5591216216216216], 3796: [0.12857142857142856, 0.0, 0.8714285714285714, 0.0, 0.0], 2988: [0.14666666666666667, 0.0, 0.8133333333333334, 0.0, 0.04], 2325: [0.21428571428571427, 0.03571428571428571, 0.75, 0.0, 0.0], 4400: [0.05398457583547558, 0.0, 0.9357326478149101, 0.0, 0.010282776349614395], 38: [0.04964539007092199, 0.0, 0.950354609929078, 0.0, 0.0], 4093: [0.15, 0.0, 0.85, 0.0, 0.0], 4070: [0.12883435582822086, 0.0, 0.8711656441717791, 0.0, 0.0], 3927: [0.12244897959183673, 0.0, 0.8775510204081632, 0.0, 0.0], 8781: [0.16614420062695925, 0.003134796238244514, 0.2884012539184953, 0.0, 0.542319749216301], 17763: [0.15151515151515152, 0.0, 0.8484848484848485, 0.0, 0.0], 11068: [0.15151515151515152, 0.0, 0.8484848484848485, 0.0, 0.0], 2481: [0.15789473684210525, 0.0, 0.8421052631578947, 0.0, 0.0], 2031: [0.1357142857142857, 0.44285714285714284, 0.4107142857142857, 0.0, 0.010714285714285714], 12552: [0.2702702702702703, 0.0, 0.7297297297297297, 0.0, 0.0], 3107: [0.2898550724637681, 0.0, 0.6956521739130435, 0.014492753623188406, 0.0], 25445: [0.18503937007874016, 0.0, 0.25196850393700787, 0.007874015748031496, 0.5551181102362205], 7031: [0.18445121951219512, 0.001524390243902439, 0.44359756097560976, 0.006097560975609756, 0.3643292682926829], 1005: [0.2736842105263158, 0.0, 0.7052631578947368, 0.0, 0.021052631578947368], 2037: [0.2747747747747748, 0.04954954954954955, 0.31981981981981983, 0.0, 0.35585585585585583], 22: [0.8258064516129032, 0.04516129032258064, 0.12903225806451613, 0.0, 0.0], 2052: [0.20253164556962025, 0.34177215189873417, 0.45569620253164556, 0.0, 0.0], 2571: [0.21739130434782608, 0.13043478260869565, 0.6521739130434783, 0.0, 0.0], 1096: [0.13333333333333333, 0.011111111111111112, 0.8555555555555555, 0.0, 0.0], 12734: [0.16666666666666666, 0.0, 0.8333333333333334, 0.0, 0.0], 7729: [0.0, 0.05263157894736842, 0.9473684210526315, 0.0, 0.0], 22892: [0.20833333333333334, 0.08333333333333333, 0.7083333333333334, 0.0, 0.0], 10774: [0.25925925925925924, 0.4444444444444444, 0.2962962962962963, 0.0, 0.0], 22570: [0.1111111111111111, 0.0, 0.8888888888888888, 0.0, 0.0], 5945: [0.16055045871559634, 0.0, 0.26146788990825687, 0.0, 0.5779816513761468], 2000: [0.15755627009646303, 0.022508038585209004, 0.39228295819935693, 0.0, 0.42765273311897106], 4364: [0.1523809523809524, 0.004761904761904762, 0.3, 0.0, 0.5428571428571428], 13949: [0.12371134020618557, 0.23711340206185566, 0.23711340206185566, 0.0, 0.4020618556701031], 2002: [0.15207373271889402, 0.004608294930875576, 0.30414746543778803, 0.0, 0.5391705069124424], 2168: [0.21311475409836064, 0.0, 0.2786885245901639, 0.0, 0.5081967213114754], 8649: [0.13333333333333333, 0.0, 0.7777777777777778, 0.0, 0.08888888888888889], 17720: [0.0, 0.0, 0.8823529411764706, 0.0, 0.11764705882352941], 3354: [0.2, 0.2, 0.6, 0.0, 0.0], 2171: [0.058823529411764705, 0.0, 0.9411764705882353, 0.0, 0.0], 4534: [0.35, 0.0, 0.65, 0.0, 0.0], 8206: [0.875, 0.0, 0.125, 0.0, 0.0], 1091: [0.5, 0.0, 0.5, 0.0, 0.0], 2012: [0.5, 0.08333333333333333, 0.3333333333333333, 0.08333333333333333, 0.0], 30957: [0.2857142857142857, 0.0, 0.7142857142857143, 0.0, 0.0], 1982: [0.0, 0.6470588235294118, 0.35294117647058826, 0.0, 0.0], 5274: [0.1875, 0.0, 0.7291666666666666, 0.0, 0.08333333333333333], 2074: [0.569620253164557, 0.05907172995780591, 0.35443037974683544, 0.008438818565400843, 0.008438818565400843], 8091: [0.5064102564102564, 0.03205128205128205, 0.42948717948717946, 0.01282051282051282, 0.019230769230769232], 8297: [0.17647058823529413, 0.0, 0.8137254901960784, 0.00980392156862745, 0.0], 26518: [0.16666666666666666, 0.0, 0.8333333333333334, 0.0, 0.0], 1986: [0.145, 0.675, 0.175, 0.0, 0.005], 7479: [0.041916167664670656, 0.041916167664670656, 0.9161676646706587, 0.0, 0.0], 39: [0.07731958762886598, 0.005154639175257732, 0.9175257731958762, 0.0, 0.0], 17104: [0.3392857142857143, 0.125, 0.5238095238095238, 0.0, 0.011904761904761904], 17494: [0.14457831325301204, 0.0, 0.8554216867469879, 0.0, 0.0], 30140: [0.06349206349206349, 0.0, 0.9365079365079365, 0.0, 0.0], 31613: [0.0963855421686747, 0.0, 0.9036144578313253, 0.0, 0.0], 5743: [0.15846994535519127, 0.26229508196721313, 0.5737704918032787, 0.00546448087431694, 0.0], 3233: [0.13963963963963963, 0.35135135135135137, 0.5045045045045045, 0.0045045045045045045, 0.0], 2846: [0.18433179723502305, 0.3548387096774194, 0.45161290322580644, 0.0, 0.009216589861751152], 6350: [0.11214953271028037, 0.42990654205607476, 0.43457943925233644, 0.0, 0.02336448598130841], 4746: [0.11439114391143912, 0.34686346863468637, 0.4095940959409594, 0.0036900369003690036, 0.12546125461254612], 18258: [0.1620879120879121, 0.5467032967032966, 0.2664835164835165, 0.0027472527472527475, 0.02197802197802198], 8650: [0.15748031496062992, 0.5643044619422573, 0.2545931758530184, 0.0026246719160104987, 0.02099737532808399], 1985: [0.13580246913580246, 0.30864197530864196, 0.5061728395061729, 0.0, 0.04938271604938271], 26349: [0.10526315789473684, 0.0, 0.8947368421052632, 0.0, 0.0], 2435: [0.189873417721519, 0.0, 0.810126582278481, 0.0, 0.0], 26904: [0.15789473684210525, 0.0, 0.8421052631578947, 0.0, 0.0], 22958: [0.15789473684210525, 0.0, 0.8421052631578947, 0.0, 0.0], 14207: [0.16230366492146597, 0.005235602094240838, 0.8324607329842932, 0.0, 0.0], 1980: [0.2389937106918239, 0.3270440251572327, 0.4276729559748428, 0.0, 0.006289308176100629], 2446: [0.15471698113207547, 0.0, 0.37735849056603776, 0.0037735849056603774, 0.4641509433962264], 10297: [0.16612377850162866, 0.0, 0.4234527687296417, 0.003257328990228013, 0.40716612377850164], 2872: [0.12666666666666668, 0.0, 0.21333333333333335, 0.0, 0.66], 21769: [0.9372822299651568, 0.013937282229965157, 0.03832752613240418, 0.006968641114982578, 0.003484320557491289], 1990: [0.08376963350785341, 0.4607329842931937, 0.44502617801047123, 0.0, 0.010471204188481676], 5399: [0.06666666666666667, 0.0, 0.9333333333333333, 0.0, 0.0], 3416: [0.10989010989010989, 0.6263736263736264, 0.26373626373626374, 0.0, 0.0], 1048: [0.17757009345794392, 0.6915887850467289, 0.12149532710280374, 0.0, 0.009345794392523364], 2127: [0.3333333333333333, 0.1111111111111111, 0.5555555555555556, 0.0, 0.0], 26946: [0.2972972972972973, 0.02702702702702703, 0.6756756756756757, 0.0, 0.0], 3638: [0.0625, 0.0625, 0.875, 0.0, 0.0], 17396: [0.13636363636363635, 0.0, 0.8636363636363636, 0.0, 0.0], 9266: [0.21176470588235294, 0.0, 0.788235294117647, 0.0, 0.0], 4627: [0.23880597014925373, 0.0, 0.7611940298507462, 0.0, 0.0], 16930: [0.21428571428571427, 0.0, 0.7142857142857143, 0.0, 0.07142857142857142], 6688: [0.1951219512195122, 0.0, 0.7560975609756098, 0.0, 0.04878048780487805], 1025: [0.12037037037037036, 0.1111111111111111, 0.6666666666666666, 0.0, 0.10185185185185185], 27500: [0.0, 0.15384615384615385, 0.8461538461538461, 0.0, 0.0], 7740: [0.0, 0.0, 1.0, 0.0, 0.0], 16720: [0.04, 0.04, 0.92, 0.0, 0.0], 1009: [0.08383233532934131, 0.17964071856287425, 0.6826347305389222, 0.029940119760479042, 0.023952095808383235], 7670: [0.14285714285714285, 0.0, 0.8571428571428571, 0.0, 0.0], 2077: [0.16, 0.0, 0.84, 0.0, 0.0], 27162: [0.14814814814814814, 0.12345679012345678, 0.7283950617283951, 0.0, 0.0], 3832: [0.2727272727272727, 0.0, 0.7272727272727273, 0.0, 0.0], 11139: [0.2, 0.0, 0.8, 0.0, 0.0], 20177: [0.030303030303030304, 0.0, 0.4393939393939394, 0.0, 0.5303030303030303], 18377: [0.21428571428571427, 0.5, 0.25, 0.0, 0.03571428571428571], 8189: [0.0, 0.0, 1.0, 0.0, 0.0], 1991: [0.15151515151515152, 0.21212121212121213, 0.5757575757575758, 0.0, 0.06060606060606061], 2439: [0.23809523809523808, 0.0, 0.7619047619047619, 0.0, 0.0], 4090: [0.20245398773006135, 0.0, 0.6319018404907976, 0.006134969325153374, 0.15950920245398773], 11897: [0.23636363636363636, 0.0, 0.7636363636363637, 0.0, 0.0], 13642: [0.23036649214659685, 0.0, 0.7696335078534031, 0.0, 0.0], 1072: [0.23036649214659685, 0.0, 0.7696335078534031, 0.0, 0.0], 40: [0.13333333333333333, 0.0, 0.8666666666666667, 0.0, 0.0], 3937: [0.03125, 0.0, 0.96875, 0.0, 0.0], 28886: [0.5370370370370371, 0.018518518518518517, 0.4398148148148148, 0.0, 0.004629629629629629], 1028: [0.4459016393442623, 0.07540983606557378, 0.45901639344262296, 0.0, 0.019672131147540985], 24614: [0.45454545454545453, 0.0, 0.5454545454545454, 0.0, 0.0], 12922: [0.42857142857142855, 0.0, 0.5714285714285714, 0.0, 0.0], 3980: [0.5, 0.0, 0.5, 0.0, 0.0], 4737: [0.16097560975609757, 0.0, 0.00975609756097561, 0.0, 0.8292682926829268], 3713: [0.25, 0.015625, 0.171875, 0.0, 0.5625], 2072: [0.19753086419753085, 0.053497942386831275, 0.4156378600823045, 0.00411522633744856, 0.3292181069958848], 7635: [0.16666666666666666, 0.014705882352941176, 0.6029411764705882, 0.0, 0.21568627450980393], 8066: [0.17708333333333334, 0.015625, 0.578125, 0.0, 0.22916666666666666], 1996: [0.3111111111111111, 0.17777777777777778, 0.5111111111111111, 0.0, 0.0], 6025: [0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.0], 4332: [0.6083333333333333, 0.0, 0.36666666666666664, 0.008333333333333333, 0.016666666666666666], 9557: [0.48484848484848486, 0.09090909090909091, 0.3333333333333333, 0.030303030303030304, 0.06060606060606061], 5710: [0.5769230769230769, 0.07692307692307693, 0.34615384615384615, 0.0, 0.0], 2045: [0.16847826086956522, 0.002717391304347826, 0.17391304347826086, 0.010869565217391304, 0.6440217391304348], 37: [0.0410958904109589, 0.0547945205479452, 0.9041095890410958, 0.0, 0.0], 4044: [0.1875, 0.0, 0.5, 0.0, 0.3125], 2556: [0.18032786885245902, 0.0, 0.5081967213114754, 0.0, 0.3114754098360656], 9053: [0.056179775280898875, 0.0, 0.9438202247191011, 0.0, 0.0], 1007: [0.5667752442996743, 0.05863192182410423, 0.3550488599348534, 0.019543973941368076, 0.0], 2055: [0.08695652173913043, 0.1565217391304348, 0.7304347826086957, 0.017391304347826087, 0.008695652173913044], 1023: [0.06818181818181818, 0.03409090909090909, 0.8636363636363636, 0.0, 0.03409090909090909], 6318: [0.14285714285714285, 0.0, 0.8571428571428571, 0.0, 0.0], 3341: [0.45161290322580644, 0.0, 0.5161290322580645, 0.03225806451612903, 0.0], 3870: [0.15730337078651685, 0.19101123595505617, 0.651685393258427, 0.0, 0.0], 3226: [0.0625, 0.0, 0.9375, 0.0, 0.0], 2836: [0.10810810810810811, 0.05405405405405406, 0.8378378378378378, 0.0, 0.0], 9496: [0.1590909090909091, 0.0, 0.8409090909090909, 0.0, 0.0], 9299: [0.4166666666666667, 0.0, 0.5833333333333334, 0.0, 0.0], 2409: [0.4117647058823529, 0.0, 0.5588235294117647, 0.0, 0.029411764705882353], 5674: [0.4090909090909091, 0.0, 0.5909090909090909, 0.0, 0.0], 2706: [0.7297297297297297, 0.0, 0.2702702702702703, 0.0, 0.0], 29: [0.2222222222222222, 0.1111111111111111, 0.6666666666666666, 0.0, 0.0], 5390: [0.0, 0.0, 1.0, 0.0, 0.0], 2112: [0.8518518518518519, 0.0, 0.13580246913580246, 0.0, 0.012345679012345678], 2776: [0.09239130434782608, 0.904891304347826, 0.002717391304347826, 0.0, 0.0], 22169: [0.09207161125319693, 0.9053708439897699, 0.0025575447570332483, 0.0, 0.0], 2008: [0.10337972166998012, 0.8469184890656064, 0.02982107355864811, 0.0019880715705765406, 0.017892644135188866], 72: [0.1111111111111111, 0.05555555555555555, 0.8333333333333334, 0.0, 0.0], 21505: [0.08333333333333333, 0.0, 0.9166666666666666, 0.0, 0.0], 16: [0.19509345794392524, 0.19509345794392524, 0.1133177570093458, 0.0, 0.49649532710280375], 3205: [0.18181818181818182, 0.0, 0.8181818181818182, 0.0, 0.0], 12697: [0.15714285714285714, 0.0, 0.4857142857142857, 0.0, 0.35714285714285715], 9676: [0.11428571428571428, 0.005194805194805195, 0.08831168831168831, 0.0025974025974025974, 0.7896103896103897], 20597: [0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.0], 2696: [0.5333333333333333, 0.0, 0.4666666666666667, 0.0, 0.0], 2198: [0.2, 0.1, 0.7, 0.0, 0.0], 17: [0.22746781115879827, 0.51931330472103, 0.22317596566523606, 0.004291845493562232, 0.02575107296137339], 3825: [0.2894736842105263, 0.0, 0.7105263157894737, 0.0, 0.0], 15751: [0.2894736842105263, 0.0, 0.7105263157894737, 0.0, 0.0], 2400: [0.35185185185185186, 0.05555555555555555, 0.5925925925925926, 0.0, 0.0], 4134: [0.17567567567567569, 0.0, 0.8243243243243243, 0.0, 0.0], 22686: [0.17333333333333334, 0.0, 0.8266666666666667, 0.0, 0.0], 7407: [0.22727272727272727, 0.0, 0.45454545454545453, 0.0, 0.3181818181818182], 1066: [0.13953488372093023, 0.0, 0.6976744186046512, 0.0, 0.16279069767441862], 3503: [0.25, 0.0, 0.3125, 0.0, 0.4375], 9158: [0.9090909090909091, 0.0, 0.09090909090909091, 0.0, 0.0], 4164: [0.9090909090909091, 0.0, 0.09090909090909091, 0.0, 0.0], 1051: [0.9, 0.0, 0.1, 0.0, 0.0], 14931: [0.4, 0.0, 0.6, 0.0, 0.0], 2862: [0.125, 0.0, 0.8125, 0.0625, 0.0], 12703: [0.7619047619047619, 0.09523809523809523, 0.14285714285714285, 0.0, 0.0], 2133: [0.69, 0.0, 0.26, 0.04, 0.01], 3406: [0.0, 0.0, 1.0, 0.0, 0.0], 4341: [0.046153846153846156, 0.5076923076923077, 0.26153846153846155, 0.0, 0.18461538461538463], 2259: [0.0, 0.0, 0.5555555555555556, 0.0, 0.4444444444444444], 27: [0.1, 0.0, 0.9, 0.0, 0.0], 14191: [0.6785714285714286, 0.03571428571428571, 0.2857142857142857, 0.0, 0.0], 5880: [0.1, 0.0, 0.9, 0.0, 0.0], 2550: [0.13575865128660158, 0.8509316770186336, 0.013309671694764862, 0.0, 0.0], 20702: [0.0, 0.0, 1.0, 0.0, 0.0], 3234: [0.16666666666666666, 0.0, 0.8333333333333334, 0.0, 0.0], 9901: [0.1794871794871795, 0.05128205128205128, 0.7692307692307693, 0.0, 0.0], 11374: [0.21818181818181817, 0.0, 0.6727272727272727, 0.0, 0.10909090909090909], 26279: [0.7333333333333333, 0.0, 0.26666666666666666, 0.0, 0.0], 20080: [0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 0.0], 14346: [0.8823529411764706, 0.0, 0.11764705882352941, 0.0, 0.0], 16777: [0.4864864864864865, 0.21621621621621623, 0.2972972972972973, 0.0, 0.0], 4778: [0.42857142857142855, 0.14285714285714285, 0.42857142857142855, 0.0, 0.0], 2970: [0.6153846153846154, 0.15384615384615385, 0.15384615384615385, 0.07692307692307693, 0.0], 8264: [0.1875, 0.6875, 0.125, 0.0, 0.0], 13: [0.47058823529411764, 0.058823529411764705, 0.36764705882352944, 0.10294117647058823, 0.0], 8638: [0.17391304347826086, 0.6521739130434783, 0.13043478260869565, 0.0, 0.043478260869565216], 3241: [0.1, 0.0, 0.9, 0.0, 0.0], 14372: [0.8333333333333334, 0.0, 0.1388888888888889, 0.0, 0.027777777777777776], 12555: [0.8387096774193549, 0.0, 0.16129032258064516, 0.0, 0.0], 1024: [0.28535353535353536, 0.4898989898989899, 0.18181818181818182, 0.0025252525252525255, 0.04040404040404041], 17218: [0.4, 0.0, 0.6, 0.0, 0.0], 10445: [0.2542372881355932, 0.0, 0.423728813559322, 0.0, 0.3220338983050847], 12133: [0.3, 0.6, 0.1, 0.0, 0.0], 18473: [0.17647058823529413, 0.17647058823529413, 0.29411764705882354, 0.0, 0.35294117647058826], 5492: [0.09523809523809523, 0.0, 0.9047619047619048, 0.0, 0.0], 3056: [0.2, 0.0, 0.8, 0.0, 0.0], 3367: [0.2, 0.0, 0.8, 0.0, 0.0], 1027: [0.18181818181818182, 0.09090909090909091, 0.7272727272727273, 0.0, 0.0], 2974: [0.09090909090909091, 0.0, 0.9090909090909091, 0.0, 0.0], 2899: [0.058823529411764705, 0.0, 0.9411764705882353, 0.0, 0.0], 3386: [0.19047619047619047, 0.0, 0.7619047619047619, 0.047619047619047616, 0.0], 4983: [0.08571428571428572, 0.17142857142857143, 0.7142857142857143, 0.02857142857142857, 0.0], 1006: [0.10909090909090909, 0.4909090909090909, 0.39090909090909093, 0.00909090909090909, 0.0], 2815: [0.14285714285714285, 0.0, 0.7619047619047619, 0.09523809523809523, 0.0], 24330: [0.14285714285714285, 0.0, 0.7619047619047619, 0.09523809523809523, 0.0], 13517: [0.0, 0.0, 1.0, 0.0, 0.0], 2066: [0.0, 0.0, 1.0, 0.0, 0.0], 9339: [0.0, 0.0, 1.0, 0.0, 0.0], 2524: [0.5531914893617021, 0.02127659574468085, 0.425531914893617, 0.0, 0.0], 9035: [0.78, 0.0, 0.22, 0.0, 0.0], 12: [0.42962962962962964, 0.044444444444444446, 0.45925925925925926, 0.06666666666666667, 0.0], 2038: [0.711864406779661, 0.01694915254237288, 0.2542372881355932, 0.01694915254237288, 0.0], 4882: [0.3, 0.05, 0.6, 0.05, 0.0], 2592: [0.18518518518518517, 0.0, 0.8148148148148148, 0.0, 0.0], 20429: [0.25, 0.0, 0.75, 0.0, 0.0], 13002: [0.16666666666666666, 0.0, 0.5833333333333334, 0.0, 0.25], 2542: [0.125, 0.0, 0.875, 0.0, 0.0], 3258: [0.06666666666666667, 0.0, 0.9333333333333333, 0.0, 0.0], 13135: [0.10755679184051924, 0.8715808993973111, 0.019935095039406582, 0.0004636068613815484, 0.0004636068613815484], 9829: [0.058823529411764705, 0.0, 0.9411764705882353, 0.0, 0.0], 18566: [0.0, 0.0, 1.0, 0.0, 0.0], 2662: [0.0, 0.0, 1.0, 0.0, 0.0], 29296: [0.2, 0.0, 0.4, 0.0, 0.4], 9102: [0.16666666666666666, 0.0, 0.8333333333333334, 0.0, 0.0], 23271: [0.16666666666666666, 0.0, 0.8333333333333334, 0.0, 0.0], 2058: [0.52, 0.0, 0.48, 0.0, 0.0], 8309: [0.05555555555555555, 0.8333333333333334, 0.1111111111111111, 0.0, 0.0], 27510: [0.1079136690647482, 0.8489208633093526, 0.04316546762589928, 0.0, 0.0], 11: [0.14814814814814814, 0.13580246913580246, 0.7160493827160493, 0.0, 0.0], 3358: [0.18181818181818182, 0.0, 0.8181818181818182, 0.0, 0.0], 2293: [0.4, 0.0, 0.4, 0.0, 0.2], 12307: [0.06896551724137931, 0.0, 0.9310344827586207, 0.0, 0.0], 25278: [0.06451612903225806, 0.0, 0.9354838709677419, 0.0, 0.0], 4007: [0.0, 0.0, 1.0, 0.0, 0.0], 1978: [0.1346153846153846, 0.7307692307692307, 0.11538461538461539, 0.019230769230769232, 0.0], 21859: [0.0625, 0.0, 0.9375, 0.0, 0.0], 13249: [0.18181818181818182, 0.0, 0.8181818181818182, 0.0, 0.0], 21472: [0.5666666666666667, 0.03333333333333333, 0.4, 0.0, 0.0], 11535: [0.8627450980392157, 0.0196078431372549, 0.08823529411764706, 0.0196078431372549, 0.00980392156862745], 23: [0.7727272727272727, 0.1038961038961039, 0.12337662337662338, 0.0, 0.0], 22162: [0.24528301886792453, 0.0, 0.4339622641509434, 0.0, 0.32075471698113206], 48: [0.25862068965517243, 0.0, 0.43103448275862066, 0.0, 0.3103448275862069], 5205: [0.2711864406779661, 0.0, 0.423728813559322, 0.0, 0.3050847457627119], 6171: [0.0, 0.0, 1.0, 0.0, 0.0], 2114: [0.6578947368421053, 0.0, 0.34210526315789475, 0.0, 0.0], 10657: [0.4312796208530806, 0.0, 0.17535545023696683, 0.0, 0.3933649289099526], 6509: [0.4906832298136646, 0.2795031055900621, 0.22981366459627328, 0.0, 0.0], 6655: [0.06299212598425197, 0.31496062992125984, 0.3464566929133858, 0.0, 0.2755905511811024], 11965: [0.0, 0.75, 0.25, 0.0, 0.0], 6266: [0.20754716981132076, 0.0, 0.7547169811320755, 0.0, 0.03773584905660377], 29244: [0.14285714285714285, 0.42857142857142855, 0.14285714285714285, 0.0, 0.2857142857142857], 2735: [0.14814814814814814, 0.2222222222222222, 0.5555555555555556, 0.0, 0.07407407407407407], 1974: [0.11538461538461539, 0.7307692307692307, 0.15384615384615385, 0.0, 0.0], 4303: [0.13333333333333333, 0.2, 0.4, 0.26666666666666666, 0.0], 2887: [0.14285714285714285, 0.14285714285714285, 0.42857142857142855, 0.2857142857142857, 0.0], 2268: [0.125, 0.0, 0.625, 0.25, 0.0], 9876: [0.08695652173913043, 0.0, 0.6521739130434783, 0.0, 0.2608695652173913], 2063: [0.32142857142857145, 0.0, 0.6428571428571429, 0.0, 0.03571428571428571], 3158: [0.0, 0.25, 0.625, 0.0, 0.125], 24542: [0.10526315789473684, 0.0, 0.05921052631578947, 0.0, 0.8355263157894737], 4060: [0.13793103448275862, 0.004310344827586207, 0.03879310344827586, 0.0, 0.8189655172413793], 1030: [0.15151515151515152, 0.045454545454545456, 0.15151515151515152, 0.0, 0.6515151515151515], 70: [0.4, 0.0, 0.6, 0.0, 0.0], 8233: [0.3888888888888889, 0.05555555555555555, 0.5555555555555556, 0.0, 0.0], 3245: [0.23076923076923078, 0.23076923076923078, 0.5384615384615384, 0.0, 0.0], 6086: [0.0, 0.0, 1.0, 0.0, 0.0], 12732: [0.0, 0.0, 0.8333333333333334, 0.16666666666666666, 0.0], 2483: [0.14285714285714285, 0.2857142857142857, 0.5714285714285714, 0.0, 0.0], 1008: [0.16883116883116883, 0.09090909090909091, 0.5974025974025974, 0.06493506493506493, 0.07792207792207792], 7864: [0.05555555555555555, 0.0, 0.9444444444444444, 0.0, 0.0], 10354: [0.125, 0.0, 0.875, 0.0, 0.0], 1119: [0.0, 0.0, 1.0, 0.0, 0.0], 12031: [0.2608695652173913, 0.0, 0.7391304347826086, 0.0, 0.0], 1038: [0.23684210526315788, 0.0, 0.7105263157894737, 0.05263157894736842, 0.0], 1037: [0.2894736842105263, 0.0, 0.6578947368421053, 0.05263157894736842, 0.0], 1092: [0.0, 0.16666666666666666, 0.8333333333333334, 0.0, 0.0], 9399: [0.1934156378600823, 0.6790123456790124, 0.06995884773662552, 0.00411522633744856, 0.053497942386831275], 3452: [0.07692307692307693, 0.0, 0.9230769230769231, 0.0, 0.0], 13261: [0.14285714285714285, 0.0, 0.8571428571428571, 0.0, 0.0], 84: [0.24324324324324326, 0.0, 0.6486486486486487, 0.0, 0.10810810810810811], 8135: [0.2765957446808511, 0.0, 0.6382978723404256, 0.0, 0.0851063829787234], 2720: [0.0, 0.0, 0.4, 0.2, 0.4], 19858: [0.0, 0.0, 0.875, 0.125, 0.0], 9504: [0.0, 0.0, 1.0, 0.0, 0.0], 6584: [0.14285714285714285, 0.0, 0.8571428571428571, 0.0, 0.0], 6616: [0.0, 0.0, 1.0, 0.0, 0.0], 4554: [0.0, 0.0, 1.0, 0.0, 0.0], 6114: [0.0, 0.0, 1.0, 0.0, 0.0], 3340: [0.9083333333333333, 0.0, 0.09166666666666666, 0.0, 0.0], 3057: [0.25, 0.0, 0.75, 0.0, 0.0], 71: [0.034482758620689655, 0.0, 0.9655172413793104, 0.0, 0.0], 2401: [0.0, 0.0, 1.0, 0.0, 0.0], 5603: [0.42105263157894735, 0.0, 0.5789473684210527, 0.0, 0.0], 3445: [0.5384615384615384, 0.0, 0.46153846153846156, 0.0, 0.0], 3139: [0.5714285714285714, 0.0, 0.42857142857142855, 0.0, 0.0], 17792: [0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.0], 7408: [0.1509433962264151, 0.7924528301886793, 0.05660377358490566, 0.0, 0.0], 4253: [0.25925925925925924, 0.07407407407407407, 0.6666666666666666, 0.0, 0.0], 30766: [0.16129032258064516, 0.0, 0.8387096774193549, 0.0, 0.0], 14983: [0.15873015873015872, 0.0, 0.07142857142857142, 0.0, 0.7698412698412699], 30284: [0.08396946564885496, 0.0, 0.12213740458015267, 0.0, 0.7938931297709924], 11296: [0.35, 0.6, 0.05, 0.0, 0.0], 29561: [0.2, 0.0, 0.8, 0.0, 0.0], 8079: [0.14285714285714285, 0.07142857142857142, 0.7857142857142857, 0.0, 0.0], 10667: [0.07692307692307693, 0.07692307692307693, 0.8461538461538461, 0.0, 0.0], 2064: [0.07692307692307693, 0.07692307692307693, 0.8461538461538461, 0.0, 0.0], 8759: [0.10810810810810811, 0.0, 0.13513513513513514, 0.0, 0.7567567567567568], 13102: [0.09433962264150944, 0.3867924528301887, 0.14150943396226415, 0.0, 0.37735849056603776], 2764: [0.0847457627118644, 0.0, 0.23728813559322035, 0.0, 0.6779661016949152], 3132: [0.12962962962962962, 0.0, 0.12962962962962962, 0.0, 0.7407407407407407], 23826: [0.21875, 0.0, 0.34375, 0.0625, 0.375], 7846: [0.25806451612903225, 0.03225806451612903, 0.3225806451612903, 0.0, 0.3870967741935484], 5680: [0.0, 0.4, 0.6, 0.0, 0.0], 17632: [0.45454545454545453, 0.09090909090909091, 0.36363636363636365, 0.09090909090909091, 0.0], 2047: [0.0, 0.0, 0.3, 0.0, 0.7], 2499: [0.1, 0.3, 0.6, 0.0, 0.0], 8186: [0.13333333333333333, 0.0, 0.8666666666666667, 0.0, 0.0], 12340: [0.32432432432432434, 0.5405405405405406, 0.12162162162162163, 0.013513513513513514, 0.0], 21309: [0.3125, 0.25, 0.4375, 0.0, 0.0], 4744: [0.043478260869565216, 0.0, 0.7391304347826086, 0.0, 0.21739130434782608], 3284: [0.2777777777777778, 0.5, 0.2222222222222222, 0.0, 0.0], 2026: [0.2, 0.6666666666666666, 0.13333333333333333, 0.0, 0.0], 25: [0.7387387387387387, 0.07207207207207207, 0.1891891891891892, 0.0, 0.0], 20626: [0.07042253521126761, 0.8732394366197183, 0.04929577464788732, 0.007042253521126761, 0.0], 7765: [0.4166666666666667, 0.08333333333333333, 0.5, 0.0, 0.0], 20595: [0.946969696969697, 0.0, 0.05303030303030303, 0.0, 0.0], 2092: [0.8333333333333334, 0.0, 0.16666666666666666, 0.0, 0.0], 13198: [0.3076923076923077, 0.038461538461538464, 0.6153846153846154, 0.038461538461538464, 0.0], 4005: [0.5483870967741935, 0.03225806451612903, 0.25806451612903225, 0.0, 0.16129032258064516], 3350: [0.5555555555555556, 0.0, 0.4444444444444444, 0.0, 0.0], 5016: [0.4444444444444444, 0.0, 0.5555555555555556, 0.0, 0.0], 23295: [0.1111111111111111, 0.0, 0.05555555555555555, 0.0, 0.8333333333333334], 3308: [0.0, 0.0, 1.0, 0.0, 0.0], 19938: [0.375, 0.0, 0.625, 0.0, 0.0], 21: [0.32, 0.32, 0.36, 0.0, 0.0], 6387: [0.046875, 0.5, 0.453125, 0.0, 0.0], 6112: [0.36363636363636365, 0.0, 0.6363636363636364, 0.0, 0.0], 6187: [0.25, 0.375, 0.375, 0.0, 0.0], 4896: [0.058823529411764705, 0.0, 0.5294117647058824, 0.0, 0.4117647058823529], 9071: [0.2, 0.36, 0.44, 0.0, 0.0], 2408: [0.17857142857142858, 0.32142857142857145, 0.5, 0.0, 0.0], 26: [0.1, 0.1, 0.8, 0.0, 0.0], 4667: [0.4444444444444444, 0.0, 0.5555555555555556, 0.0, 0.0], 7971: [0.125, 0.0, 0.875, 0.0, 0.0], 3217: [0.7096774193548387, 0.04838709677419355, 0.14516129032258066, 0.016129032258064516, 0.08064516129032258], 5049: [0.7608695652173914, 0.06521739130434782, 0.17391304347826086, 0.0, 0.0], 4867: [0.2, 0.0, 0.8, 0.0, 0.0], 28: [0.0, 0.0, 1.0, 0.0, 0.0], 3075: [0.047619047619047616, 0.7619047619047619, 0.19047619047619047, 0.0, 0.0], 4273: [0.2, 0.2, 0.6, 0.0, 0.0], 18073: [0.08943089430894309, 0.0, 0.06504065040650407, 0.0, 0.8455284552845529], 8873: [0.11148648648648649, 0.8817567567567568, 0.005067567567567568, 0.0016891891891891893, 0.0], 24: [0.8795811518324608, 0.05759162303664921, 0.06282722513089005, 0.0, 0.0], 2515: [0.0, 0.0, 1.0, 0.0, 0.0], 23343: [0.5714285714285714, 0.14285714285714285, 0.2857142857142857, 0.0, 0.0], 9353: [0.24, 0.72, 0.04, 0.0, 0.0], 14921: [0.5, 0.0, 0.5, 0.0, 0.0], 14673: [0.2, 0.0, 0.8, 0.0, 0.0], 4377: [0.5, 0.125, 0.375, 0.0, 0.0], 6261: [0.23809523809523808, 0.3333333333333333, 0.42857142857142855, 0.0, 0.0], 13410: [0.782608695652174, 0.0, 0.21739130434782608, 0.0, 0.0], 3536: [0.0, 0.0, 1.0, 0.0, 0.0], 13674: [0.2222222222222222, 0.0, 0.7777777777777778, 0.0, 0.0], 2123: [0.875, 0.0625, 0.0625, 0.0, 0.0], 30131: [0.125, 0.0, 0.875, 0.0, 0.0], 31448: [0.0, 0.8571428571428571, 0.14285714285714285, 0.0, 0.0], 23311: [0.4, 0.0, 0.6, 0.0, 0.0], 10351: [0.2, 0.0, 0.8, 0.0, 0.0], 5051: [0.17647058823529413, 0.2647058823529412, 0.35294117647058826, 0.0, 0.20588235294117646], 3008: [0.11764705882352941, 0.8529411764705882, 0.029411764705882353, 0.0, 0.0], 1975: [0.42857142857142855, 0.0, 0.42857142857142855, 0.0, 0.14285714285714285], 2161: [0.375, 0.0, 0.625, 0.0, 0.0], 1992: [0.734789391575663, 0.0390015600624025, 0.0218408736349454, 0.0, 0.20436817472698907], 30433: [0.5714285714285714, 0.0, 0.42857142857142855, 0.0, 0.0], 49: [0.8472222222222222, 0.06944444444444445, 0.08333333333333333, 0.0, 0.0], 29998: [0.0, 0.0, 1.0, 0.0, 0.0], 5795: [0.6, 0.0, 0.4, 0.0, 0.0], 2078: [0.0, 0.8, 0.2, 0.0, 0.0], 16812: [0.0, 0.0, 1.0, 0.0, 0.0], 2281: [0.625, 0.0, 0.375, 0.0, 0.0], 8601: [0.4, 0.0, 0.6, 0.0, 0.0], 7230: [0.041666666666666664, 0.625, 0.3333333333333333, 0.0, 0.0], 11434: [0.14285714285714285, 0.6428571428571429, 0.21428571428571427, 0.0, 0.0], 14199: [0.14285714285714285, 0.0, 0.8571428571428571, 0.0, 0.0], 4110: [0.0, 0.0, 0.8, 0.2, 0.0], 23166: [0.9294117647058824, 0.023529411764705882, 0.047058823529411764, 0.0, 0.0], 2170: [0.9027777777777778, 0.041666666666666664, 0.05555555555555555, 0.0, 0.0], 27587: [0.16666666666666666, 0.0, 0.8333333333333334, 0.0, 0.0], 5695: [0.2, 0.0, 0.8, 0.0, 0.0], 2054: [0.8818181818181818, 0.06818181818181818, 0.031818181818181815, 0.0, 0.01818181818181818], 2154: [0.4583333333333333, 0.0, 0.5416666666666666, 0.0, 0.0], 8117: [0.14285714285714285, 0.0, 0.7142857142857143, 0.14285714285714285, 0.0], 2337: [0.044444444444444446, 0.7111111111111111, 0.24444444444444444, 0.0, 0.0], 25352: [0.09523809523809523, 0.0, 0.9047619047619048, 0.0, 0.0], 6717: [0.34285714285714286, 0.45714285714285713, 0.2, 0.0, 0.0], 2147: [0.2535211267605634, 0.3380281690140845, 0.04225352112676056, 0.0, 0.36619718309859156], 2146: [0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.0], 2140: [0.29411764705882354, 0.0, 0.7058823529411765, 0.0, 0.0], 6963: [0.0, 0.0, 1.0, 0.0, 0.0], 3628: [0.1111111111111111, 0.0, 0.3888888888888889, 0.0, 0.5], 3094: [0.0, 0.8, 0.2, 0.0, 0.0], 28639: [0.9333333333333333, 0.0, 0.06666666666666667, 0.0, 0.0], 2010: [0.9631578947368421, 0.010526315789473684, 0.005263157894736842, 0.0, 0.021052631578947368], 1034: [0.2857142857142857, 0.42857142857142855, 0.2857142857142857, 0.0, 0.0], 18452: [0.0, 0.2, 0.8, 0.0, 0.0], 5220: [0.16551724137931034, 0.7862068965517242, 0.04827586206896552, 0.0, 0.0], 28713: [0.1962025316455696, 0.4050632911392405, 0.06329113924050633, 0.0, 0.33544303797468356], 5115: [0.09090909090909091, 0.8181818181818182, 0.09090909090909091, 0.0, 0.0], 16425: [0.29411764705882354, 0.0, 0.7058823529411765, 0.0, 0.0], 4042: [0.0, 0.0, 1.0, 0.0, 0.0], 16084: [0.5, 0.16666666666666666, 0.3333333333333333, 0.0, 0.0], 8313: [0.18181818181818182, 0.0, 0.8181818181818182, 0.0, 0.0], 11631: [0.9801084990958409, 0.0054249547920434, 0.0054249547920434, 0.0, 0.009041591320072333], 1971: [0.375, 0.5625, 0.0625, 0.0, 0.0], 9630: [0.35714285714285715, 0.0, 0.07142857142857142, 0.0, 0.5714285714285714], 10999: [0.36363636363636365, 0.0, 0.09090909090909091, 0.0, 0.5454545454545454], 27698: [0.9817232375979112, 0.0, 0.0026109660574412533, 0.0, 0.015665796344647518], 27390: [0.14285714285714285, 0.42857142857142855, 0.42857142857142855, 0.0, 0.0], 2165: [0.5, 0.0, 0.5, 0.0, 0.0], 2094: [0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 0.0], 2357: [0.04, 0.76, 0.16, 0.0, 0.04], 2680: [0.8571428571428571, 0.0, 0.14285714285714285, 0.0, 0.0], 2071: [0.1111111111111111, 0.2222222222222222, 0.6666666666666666, 0.0, 0.0], 25645: [0.9344262295081968, 0.01639344262295082, 0.03278688524590164, 0.01639344262295082, 0.0], 2709: [0.9464285714285714, 0.0, 0.05357142857142857, 0.0, 0.0], 26379: [0.1981981981981982, 0.0, 0.009009009009009009, 0.04504504504504504, 0.7477477477477478], 7830: [0.08333333333333333, 0.0, 0.16666666666666666, 0.75, 0.0], 18171: [0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.0], 3567: [0.13513513513513514, 0.7837837837837838, 0.08108108108108109, 0.0, 0.0], 2049: [0.17647058823529413, 0.4117647058823529, 0.4117647058823529, 0.0, 0.0], 2258: [0.0, 0.6, 0.4, 0.0, 0.0], 2056: [0.16666666666666666, 0.0, 0.8333333333333334, 0.0, 0.0], 4827: [0.0, 0.0, 1.0, 0.0, 0.0], 12828: [0.36363636363636365, 0.0, 0.6363636363636364, 0.0, 0.0], 2688: [0.6875, 0.0, 0.3125, 0.0, 0.0], 2904: [0.6875, 0.0, 0.3125, 0.0, 0.0], 2040: [0.16666666666666666, 0.0, 0.07142857142857142, 0.0, 0.7619047619047619], 18568: [0.07692307692307693, 0.0, 0.3076923076923077, 0.0, 0.6153846153846154], 24092: [0.8923076923076924, 0.07692307692307693, 0.03076923076923077, 0.0, 0.0], 14897: [0.5625, 0.0, 0.0625, 0.0, 0.375], 5182: [0.18181818181818182, 0.2727272727272727, 0.5454545454545454, 0.0, 0.0], 25573: [0.2, 0.0, 0.4, 0.0, 0.4], 6696: [0.021996615905245348, 0.934010152284264, 0.023688663282571912, 0.0, 0.02030456852791878], 1984: [0.0, 0.0, 1.0, 0.0, 0.0], 3178: [0.7692307692307693, 0.0, 0.15384615384615385, 0.0, 0.07692307692307693], 9371: [0.1111111111111111, 0.2222222222222222, 0.5555555555555556, 0.0, 0.1111111111111111], 2027: [0.2, 0.2, 0.4, 0.0, 0.2], 5207: [0.27941176470588236, 0.5147058823529411, 0.1323529411764706, 0.0, 0.07352941176470588], 3910: [0.08695652173913043, 0.0, 0.21739130434782608, 0.0, 0.6956521739130435], 19574: [0.045454545454545456, 0.0, 0.22727272727272727, 0.0, 0.7272727272727273], 12041: [0.08333333333333333, 0.0, 0.8333333333333334, 0.0, 0.08333333333333333], 3655: [0.07692307692307693, 0.23076923076923078, 0.6153846153846154, 0.0, 0.07692307692307693], 21637: [0.0, 0.0, 1.0, 0.0, 0.0], 2238: [0.15384615384615385, 0.0, 0.38461538461538464, 0.0, 0.46153846153846156], 2441: [0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 0.0], 2030: [0.15384615384615385, 0.5384615384615384, 0.3076923076923077, 0.0, 0.0], 8184: [0.12195121951219512, 0.8292682926829268, 0.04878048780487805, 0.0, 0.0], 16846: [0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333], 12291: [0.0, 0.625, 0.375, 0.0, 0.0], 1086: [0.0, 0.0, 1.0, 0.0, 0.0], 21479: [0.5, 0.0, 0.5, 0.0, 0.0], 2004: [0.5, 0.0, 0.5, 0.0, 0.0], 23563: [0.09523809523809523, 0.6190476190476191, 0.23809523809523808, 0.047619047619047616, 0.0], 9886: [0.09523809523809523, 0.6190476190476191, 0.23809523809523808, 0.047619047619047616, 0.0], 3595: [0.09375, 0.03125, 0.03125, 0.0, 0.84375], 2838: [0.4, 0.0, 0.6, 0.0, 0.0], 14779: [0.5714285714285714, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.0], 3644: [0.12367491166077739, 0.8692579505300353, 0.00530035335689046, 0.0, 0.0017667844522968198], 2596: [0.0, 0.9285714285714286, 0.07142857142857142, 0.0, 0.0], 8980: [0.0, 0.8333333333333334, 0.16666666666666666, 0.0, 0.0], 16184: [0.2, 0.0, 0.6, 0.0, 0.2], 13999: [0.0, 0.0, 1.0, 0.0, 0.0], 2783: [0.21428571428571427, 0.0, 0.7857142857142857, 0.0, 0.0], 19799: [0.2, 0.0, 0.2, 0.0, 0.6], 5244: [0.0, 0.5, 0.5, 0.0, 0.0], 29870: [0.9741219963031423, 0.0, 0.012939001848428836, 0.0036968576709796672, 0.009242144177449169], 6223: [0.9487179487179487, 0.0, 0.038461538461538464, 0.01282051282051282, 0.0], 2458: [0.625, 0.0, 0.25, 0.125, 0.0], 19111: [0.4, 0.0, 0.4, 0.2, 0.0], 3790: [0.5, 0.0, 0.5, 0.0, 0.0], 1070: [0.9, 0.0, 0.1, 0.0, 0.0], 6479: [0.6, 0.0, 0.4, 0.0, 0.0], 3166: [0.8333333333333334, 0.0, 0.16666666666666666, 0.0, 0.0], 31242: [0.125, 0.0, 0.875, 0.0, 0.0], 2425: [0.0, 0.0, 1.0, 0.0, 0.0], 3829: [0.0, 0.0, 1.0, 0.0, 0.0], 3794: [0.0, 0.0, 0.8333333333333334, 0.16666666666666666, 0.0], 31: [0.17218543046357615, 0.8211920529801324, 0.006622516556291391, 0.0, 0.0], 15312: [0.2, 0.0, 0.8, 0.0, 0.0], 3637: [0.13157894736842105, 0.8421052631578947, 0.02631578947368421, 0.0, 0.0], 23368: [0.0, 0.0, 0.16666666666666666, 0.8333333333333334, 0.0], 24853: [0.0, 0.0, 1.0, 0.0, 0.0], 2025: [0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.0], 6564: [0.2, 0.0, 0.8, 0.0, 0.0], 5825: [0.1, 0.5, 0.4, 0.0, 0.0], 2656: [0.175, 0.0, 0.025, 0.0, 0.8], 13542: [0.8, 0.0, 0.1, 0.0, 0.1], 30668: [0.8, 0.0, 0.1, 0.0, 0.1], 3687: [0.8333333333333334, 0.0, 0.16666666666666666, 0.0, 0.0], 25013: [0.0, 0.0, 0.8571428571428571, 0.14285714285714285, 0.0], 56: [0.0, 0.0, 1.0, 0.0, 0.0], 14411: [0.0, 0.0, 1.0, 0.0, 0.0], 19445: [0.0625, 0.875, 0.0625, 0.0, 0.0], 4047: [0.2, 0.0, 0.8, 0.0, 0.0], 8553: [0.5, 0.0, 0.3333333333333333, 0.0, 0.16666666666666666], 15318: [0.09090909090909091, 0.6363636363636364, 0.2727272727272727, 0.0, 0.0], 74: [0.19230769230769232, 0.7692307692307693, 0.02564102564102564, 0.0, 0.01282051282051282], 20557: [0.189873417721519, 0.759493670886076, 0.02531645569620253, 0.012658227848101266, 0.012658227848101266], 18587: [0.5116279069767442, 0.0, 0.023255813953488372, 0.0, 0.46511627906976744], 3408: [0.23076923076923078, 0.0, 0.07692307692307693, 0.5384615384615384, 0.15384615384615385], 3283: [0.2, 0.2, 0.4, 0.2, 0.0], 26055: [0.0, 0.0, 0.75, 0.0, 0.25], 20016: [0.1079136690647482, 0.8848920863309353, 0.007194244604316547, 0.0, 0.0], 3481: [0.10309278350515463, 0.8865979381443299, 0.010309278350515464, 0.0, 0.0], 5180: [0.16666666666666666, 0.6666666666666666, 0.16666666666666666, 0.0, 0.0], 9098: [0.07692307692307693, 0.6923076923076923, 0.23076923076923078, 0.0, 0.0], 2351: [0.625, 0.0, 0.375, 0.0, 0.0], 10144: [0.8, 0.0, 0.2, 0.0, 0.0], 2080: [0.0, 0.375, 0.625, 0.0, 0.0], 69: [0.4, 0.4, 0.2, 0.0, 0.0], 2065: [0.0, 0.5714285714285714, 0.42857142857142855, 0.0, 0.0], 2736: [0.20833333333333334, 0.5, 0.20833333333333334, 0.041666666666666664, 0.041666666666666664], 3984: [0.12121212121212122, 0.0, 0.06060606060606061, 0.5454545454545454, 0.2727272727272727], 2445: [0.0, 0.0, 0.16666666666666666, 0.8333333333333334, 0.0], 21774: [0.9889908256880734, 0.0, 0.011009174311926606, 0.0, 0.0], 15602: [0.9907235621521335, 0.0, 0.00927643784786642, 0.0, 0.0], 17214: [0.9906890130353817, 0.0, 0.00931098696461825, 0.0, 0.0], 30920: [0.0, 0.0, 1.0, 0.0, 0.0], 22487: [0.7142857142857143, 0.07142857142857142, 0.21428571428571427, 0.0, 0.0], 3622: [0.4, 0.0, 0.6, 0.0, 0.0], 2267: [0.12121212121212122, 0.8484848484848485, 0.030303030303030304, 0.0, 0.0], 6075: [0.3448275862068966, 0.13793103448275862, 0.10344827586206896, 0.0, 0.41379310344827586], 9870: [0.10084033613445378, 0.8907563025210085, 0.008403361344537815, 0.0, 0.0], 2091: [0.3333333333333333, 0.4, 0.13333333333333333, 0.13333333333333333, 0.0], 8888: [0.2, 0.0, 0.2, 0.4, 0.2], 9431: [0.11764705882352941, 0.29411764705882354, 0.058823529411764705, 0.35294117647058826, 0.17647058823529413], 30: [0.9830508474576272, 0.014341590612777053, 0.002607561929595828, 0.0, 0.0], 5161: [0.20270270270270271, 0.7905405405405406, 0.006756756756756757, 0.0, 0.0], 16362: [0.42857142857142855, 0.42857142857142855, 0.14285714285714285, 0.0, 0.0], 4263: [0.05128205128205128, 0.9230769230769231, 0.02564102564102564, 0.0, 0.0], 31192: [0.0, 0.0, 0.2, 0.0, 0.8], 11407: [0.13333333333333333, 0.8444444444444444, 0.022222222222222223, 0.0, 0.0], 8617: [0.0, 0.0, 0.3333333333333333, 0.5, 0.16666666666666666], 2752: [0.9828326180257511, 0.0, 0.004291845493562232, 0.004291845493562232, 0.008583690987124463], 17944: [0.25, 0.0, 0.125, 0.625, 0.0], 7101: [0.3, 0.1, 0.1, 0.5, 0.0], 16146: [0.4, 0.2, 0.4, 0.0, 0.0], 2029: [0.125, 0.8125, 0.0625, 0.0, 0.0], 2239: [0.8333333333333334, 0.0, 0.16666666666666666, 0.0, 0.0], 19245: [0.0, 0.4, 0.6, 0.0, 0.0], 5114: [0.8, 0.0, 0.2, 0.0, 0.0], 2874: [0.13209393346379647, 0.8669275929549902, 0.0009784735812133072, 0.0, 0.0], 2415: [0.8888888888888888, 0.0, 0.05555555555555555, 0.0, 0.05555555555555555], 12401: [0.8, 0.0, 0.2, 0.0, 0.0], 2089: [0.8, 0.0, 0.2, 0.0, 0.0], 16823: [0.20967741935483872, 0.7580645161290323, 0.03225806451612903, 0.0, 0.0], 2135: [0.09375, 0.875, 0.03125, 0.0, 0.0], 5689: [0.13793103448275862, 0.8448275862068966, 0.017241379310344827, 0.0, 0.0], 9969: [0.11320754716981132, 0.8773584905660378, 0.009433962264150943, 0.0, 0.0], 8977: [0.16666666666666666, 0.6666666666666666, 0.16666666666666666, 0.0, 0.0], 2713: [0.0, 0.8571428571428571, 0.14285714285714285, 0.0, 0.0], 25064: [0.06535947712418301, 0.9215686274509803, 0.013071895424836602, 0.0, 0.0], 10870: [0.25, 0.0, 0.016666666666666666, 0.0, 0.7333333333333333], 2747: [0.0, 0.9583333333333334, 0.041666666666666664, 0.0, 0.0], 18483: [0.17573872472783825, 0.8211508553654744, 0.0015552099533437014, 0.0, 0.0015552099533437014], 10381: [0.9772727272727273, 0.0, 0.022727272727272728, 0.0, 0.0], 3526: [0.2222222222222222, 0.6666666666666666, 0.1111111111111111, 0.0, 0.0], 31757: [0.875, 0.0, 0.125, 0.0, 0.0], 31470: [0.040983606557377046, 0.9508196721311475, 0.00819672131147541, 0.0, 0.0], 1078: [0.8, 0.0, 0.2, 0.0, 0.0], 35: [0.2, 0.05, 0.0, 0.75, 0.0], 14803: [0.76, 0.0, 0.0, 0.2, 0.04], 19218: [0.6, 0.0, 0.0, 0.4, 0.0], 29066: [0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 0.0], 4726: [0.9827586206896551, 0.0, 0.0, 0.017241379310344827, 0.0], 11641: [0.14285714285714285, 0.7142857142857143, 0.0, 0.14285714285714285, 0.0], 16322: [0.0, 0.8333333333333334, 0.0, 0.16666666666666666, 0.0], 18979: [0.0, 0.8333333333333334, 0.0, 0.16666666666666666, 0.0], 5486: [0.0, 0.0, 0.0, 0.16666666666666666, 0.8333333333333334], 2048: [0.3125, 0.625, 0.0, 0.0625, 0.0], 14085: [0.2, 0.0, 0.0, 0.0, 0.8], 23658: [0.2571428571428571, 0.0, 0.0, 0.0, 0.7428571428571429], 11144: [0.12790697674418605, 0.0, 0.0, 0.0, 0.872093023255814], 11204: [0.5454545454545454, 0.0, 0.0, 0.0, 0.45454545454545453], 11146: [0.1958762886597938, 0.0, 0.0, 0.0, 0.8041237113402062], 4122: [0.234375, 0.0, 0.0, 0.0, 0.765625], 3550: [0.14285714285714285, 0.0, 0.0, 0.0, 0.8571428571428571], 7849: [0.05555555555555555, 0.8148148148148148, 0.0, 0.0, 0.12962962962962962], 30178: [0.125, 0.0, 0.0, 0.0, 0.875], 31011: [0.2, 0.0, 0.0, 0.0, 0.8], 13871: [0.2857142857142857, 0.0, 0.0, 0.0, 0.7142857142857143], 6339: [0.2222222222222222, 0.0, 0.0, 0.0, 0.7777777777777778], 15596: [0.8333333333333334, 0.0, 0.0, 0.0, 0.16666666666666666], 2382: [0.9891304347826086, 0.0, 0.0, 0.0, 0.010869565217391304], 2987: [0.18181818181818182, 0.0, 0.0, 0.0, 0.8181818181818182], 2253: [0.18181818181818182, 0.0, 0.0, 0.0, 0.8181818181818182], 2331: [0.3333333333333333, 0.0, 0.0, 0.0, 0.6666666666666666], 2761: [0.3142857142857143, 0.0, 0.0, 0.0, 0.6857142857142857], 9641: [0.1111111111111111, 0.0, 0.0, 0.0, 0.8888888888888888], 6639: [0.0, 0.0, 0.0, 0.0, 1.0], 6995: [0.0, 0.0, 0.0, 0.0, 1.0], 7875: [0.45454545454545453, 0.36363636363636365, 0.0, 0.0, 0.18181818181818182], 13189: [0.2, 0.0, 0.0, 0.0, 0.8], 2233: [0.2, 0.0, 0.0, 0.0, 0.8], 2955: [0.2, 0.0, 0.0, 0.0, 0.8], 3792: [0.9230769230769231, 0.0, 0.0, 0.0, 0.07692307692307693], 15105: [0.9, 0.0, 0.0, 0.0, 0.1], 13408: [0.8, 0.0, 0.0, 0.0, 0.2], 2516: [0.8823529411764706, 0.0, 0.0, 0.0, 0.11764705882352941], 11835: [0.6666666666666666, 0.16666666666666666, 0.0, 0.0, 0.16666666666666666], 11542: [0.6, 0.2, 0.0, 0.0, 0.2], 9404: [0.16666666666666666, 0.0, 0.0, 0.0, 0.8333333333333334], 5135: [0.14285714285714285, 0.2857142857142857, 0.0, 0.0, 0.5714285714285714], 43: [0.0, 0.7368421052631579, 0.0, 0.0, 0.2631578947368421], 8221: [0.0, 0.25, 0.0, 0.0, 0.75], 4614: [0.2, 0.2, 0.0, 0.0, 0.6], 23423: [0.3333333333333333, 0.0, 0.0, 0.0, 0.6666666666666666], 31610: [0.18181818181818182, 0.0, 0.0, 0.0, 0.8181818181818182], 19: [0.34375, 0.5625, 0.0, 0.0, 0.09375], 5005: [0.8888888888888888, 0.0, 0.0, 0.0, 0.1111111111111111], 12382: [0.64, 0.0, 0.0, 0.0, 0.36], 11187: [0.25, 0.0, 0.0, 0.0, 0.75], 21561: [0.38461538461538464, 0.5384615384615384, 0.0, 0.0, 0.07692307692307693], 12192: [0.08888888888888889, 0.8888888888888888, 0.0, 0.0, 0.022222222222222223], 3826: [0.0, 0.9375, 0.0, 0.0, 0.0625], 6129: [0.9803921568627451, 0.0, 0.0, 0.0, 0.0196078431372549], 18071: [0.9803921568627451, 0.0, 0.0, 0.0, 0.0196078431372549], 2676: [0.8, 0.0, 0.0, 0.0, 0.2], 2327: [0.8571428571428571, 0.07142857142857142, 0.0, 0.0, 0.07142857142857142], 2719: [0.15135135135135136, 0.845945945945946, 0.0, 0.0, 0.002702702702702703], 2612: [0.12732919254658384, 0.8695652173913043, 0.0, 0.0, 0.003105590062111801], 30385: [0.14, 0.8569230769230769, 0.0, 0.0, 0.003076923076923077], 9067: [0.15667311411992263, 0.839458413926499, 0.0, 0.0, 0.0038684719535783366], 2500: [0.1388888888888889, 0.8555555555555555, 0.0, 0.0, 0.005555555555555556], 2032: [0.17511520737327188, 0.8248847926267281, 0.0, 0.0, 0.0], 2104: [0.08695652173913043, 0.9130434782608695, 0.0, 0.0, 0.0], 14387: [0.18090452261306533, 0.8190954773869347, 0.0, 0.0, 0.0], 4508: [0.05555555555555555, 0.9444444444444444, 0.0, 0.0, 0.0], 8010: [0.1016949152542373, 0.8983050847457628, 0.0, 0.0, 0.0], 2356: [0.21631205673758866, 0.7836879432624113, 0.0, 0.0, 0.0], 4226: [0.11764705882352941, 0.8823529411764706, 0.0, 0.0, 0.0], 15173: [0.1111111111111111, 0.8888888888888888, 0.0, 0.0, 0.0], 16134: [0.1111111111111111, 0.8888888888888888, 0.0, 0.0, 0.0], 20973: [0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 0.0], 3312: [0.15151515151515152, 0.8484848484848485, 0.0, 0.0, 0.0], 15008: [0.36363636363636365, 0.6363636363636364, 0.0, 0.0, 0.0], 8607: [0.2962962962962963, 0.7037037037037037, 0.0, 0.0, 0.0], 9213: [0.175, 0.825, 0.0, 0.0, 0.0], 2183: [0.20430107526881722, 0.7956989247311828, 0.0, 0.0, 0.0], 10643: [0.0, 1.0, 0.0, 0.0, 0.0], 22726: [0.10638297872340426, 0.8936170212765957, 0.0, 0.0, 0.0], 2476: [0.0, 1.0, 0.0, 0.0, 0.0], 11281: [0.09523809523809523, 0.9047619047619048, 0.0, 0.0, 0.0], 7321: [0.09523809523809523, 0.9047619047619048, 0.0, 0.0, 0.0], 1981: [0.0, 1.0, 0.0, 0.0, 0.0], 15302: [0.06382978723404255, 0.9361702127659575, 0.0, 0.0, 0.0], 25630: [0.0425531914893617, 0.9574468085106383, 0.0, 0.0, 0.0], 10300: [0.0, 1.0, 0.0, 0.0, 0.0], 8485: [0.0, 1.0, 0.0, 0.0, 0.0], 7865: [0.0, 1.0, 0.0, 0.0, 0.0], 14682: [0.0, 1.0, 0.0, 0.0, 0.0], 6416: [0.21875, 0.78125, 0.0, 0.0, 0.0], 3331: [0.10526315789473684, 0.8947368421052632, 0.0, 0.0, 0.0], 13184: [0.04285714285714286, 0.9571428571428572, 0.0, 0.0, 0.0], 6317: [0.041666666666666664, 0.9583333333333334, 0.0, 0.0, 0.0], 1989: [0.2, 0.8, 0.0, 0.0, 0.0], 2102: [0.9772727272727273, 0.022727272727272728, 0.0, 0.0, 0.0], 28857: [0.21052631578947367, 0.7894736842105263, 0.0, 0.0, 0.0], 4315: [0.0, 1.0, 0.0, 0.0, 0.0], 9029: [0.0, 1.0, 0.0, 0.0, 0.0], 29613: [0.0, 1.0, 0.0, 0.0, 0.0], 2213: [0.0, 1.0, 0.0, 0.0, 0.0], 1074: [0.9982788296041308, 0.0017211703958691911, 0.0, 0.0, 0.0], 4477: [0.4666666666666667, 0.5333333333333333, 0.0, 0.0, 0.0], 11720: [0.0, 1.0, 0.0, 0.0, 0.0], 17151: [0.08333333333333333, 0.9166666666666666, 0.0, 0.0, 0.0], 14327: [0.25, 0.75, 0.0, 0.0, 0.0], 2572: [0.2857142857142857, 0.7142857142857143, 0.0, 0.0, 0.0], 9671: [0.0, 1.0, 0.0, 0.0, 0.0], 2538: [0.0, 1.0, 0.0, 0.0, 0.0], 8149: [0.05, 0.95, 0.0, 0.0, 0.0], 148: [0.23529411764705882, 0.7647058823529411, 0.0, 0.0, 0.0], 12386: [0.0, 1.0, 0.0, 0.0, 0.0], 6407: [0.0, 1.0, 0.0, 0.0, 0.0], 3435: [0.0, 1.0, 0.0, 0.0, 0.0], 4495: [0.0, 1.0, 0.0, 0.0, 0.0], 10494: [0.9982078853046595, 0.0017921146953405018, 0.0, 0.0, 0.0], 27937: [0.998211091234347, 0.0017889087656529517, 0.0, 0.0, 0.0], 4336: [0.99822695035461, 0.0017730496453900709, 0.0, 0.0, 0.0], 6830: [0.9982014388489209, 0.0017985611510791368, 0.0, 0.0, 0.0], 8304: [0.98828125, 0.01171875, 0.0, 0.0, 0.0], 3724: [0.5, 0.5, 0.0, 0.0, 0.0], 19958: [0.14285714285714285, 0.8571428571428571, 0.0, 0.0, 0.0], 14375: [0.0, 1.0, 0.0, 0.0, 0.0], 6615: [0.15384615384615385, 0.8461538461538461, 0.0, 0.0, 0.0], 17440: [0.15384615384615385, 0.8461538461538461, 0.0, 0.0, 0.0], 2568: [0.42857142857142855, 0.5714285714285714, 0.0, 0.0, 0.0], 12399: [0.0, 1.0, 0.0, 0.0, 0.0], 26598: [0.09090909090909091, 0.9090909090909091, 0.0, 0.0, 0.0], 4631: [0.14285714285714285, 0.8571428571428571, 0.0, 0.0, 0.0], 11464: [0.1, 0.9, 0.0, 0.0, 0.0], 4988: [0.13333333333333333, 0.8666666666666667, 0.0, 0.0, 0.0], 11007: [0.3684210526315789, 0.631578947368421, 0.0, 0.0, 0.0], 3844: [0.1, 0.9, 0.0, 0.0, 0.0], 5612: [0.5714285714285714, 0.42857142857142855, 0.0, 0.0, 0.0], 2884: [0.0, 1.0, 0.0, 0.0, 0.0], 31405: [0.1875, 0.8125, 0.0, 0.0, 0.0], 2792: [0.0, 1.0, 0.0, 0.0, 0.0], 11850: [0.16666666666666666, 0.8333333333333334, 0.0, 0.0, 0.0], 21900: [0.2, 0.8, 0.0, 0.0, 0.0], 3891: [0.2, 0.8, 0.0, 0.0, 0.0], 2771: [0.0, 1.0, 0.0, 0.0, 0.0], 6381: [0.0, 1.0, 0.0, 0.0, 0.0], 13459: [0.0, 1.0, 0.0, 0.0, 0.0], 9753: [0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 0.0], 5293: [0.42857142857142855, 0.5714285714285714, 0.0, 0.0, 0.0], 11250: [0.5, 0.5, 0.0, 0.0, 0.0], 25520: [0.1, 0.9, 0.0, 0.0, 0.0], 12251: [0.1, 0.9, 0.0, 0.0, 0.0], 29237: [0.0, 1.0, 0.0, 0.0, 0.0], 2019: [0.9333333333333333, 0.06666666666666667, 0.0, 0.0, 0.0], 18616: [0.0, 1.0, 0.0, 0.0, 0.0], 5875: [0.0, 1.0, 0.0, 0.0, 0.0], 11774: [0.5, 0.5, 0.0, 0.0, 0.0], 4817: [0.4, 0.6, 0.0, 0.0, 0.0], 2107: [0.25, 0.75, 0.0, 0.0, 0.0], 24140: [0.0, 1.0, 0.0, 0.0, 0.0], 9495: [0.0, 1.0, 0.0, 0.0, 0.0], 22481: [0.5, 0.5, 0.0, 0.0, 0.0], 17480: [0.2, 0.8, 0.0, 0.0, 0.0], 8652: [0.0, 1.0, 0.0, 0.0, 0.0], 9792: [0.0, 1.0, 0.0, 0.0, 0.0], 27952: [0.0, 1.0, 0.0, 0.0, 0.0], 9: [0.5, 0.5, 0.0, 0.0, 0.0], 3606: [0.6666666666666666, 0.3333333333333333, 0.0, 0.0, 0.0], 5470: [0.2, 0.8, 0.0, 0.0, 0.0], 25770: [0.8, 0.2, 0.0, 0.0, 0.0], 10757: [1.0, 0.0, 0.0, 0.0, 0.0], 3766: [1.0, 0.0, 0.0, 0.0, 0.0], 2864: [1.0, 0.0, 0.0, 0.0, 0.0], 3538: [1.0, 0.0, 0.0, 0.0, 0.0], 28525: [1.0, 0.0, 0.0, 0.0, 0.0], 1040: [1.0, 0.0, 0.0, 0.0, 0.0], 30242: [1.0, 0.0, 0.0, 0.0, 0.0], 22613: [1.0, 0.0, 0.0, 0.0, 0.0], 28820: [1.0, 0.0, 0.0, 0.0, 0.0], 1128: [1.0, 0.0, 0.0, 0.0, 0.0], 3003: [1.0, 0.0, 0.0, 0.0, 0.0], 8740: [1.0, 0.0, 0.0, 0.0, 0.0], 15612: [1.0, 0.0, 0.0, 0.0, 0.0], 5610: [1.0, 0.0, 0.0, 0.0, 0.0], 19513: [1.0, 0.0, 0.0, 0.0, 0.0], 25719: [1.0, 0.0, 0.0, 0.0, 0.0], 7065: [1.0, 0.0, 0.0, 0.0, 0.0], 7680: [1.0, 0.0, 0.0, 0.0, 0.0], 6632: [1.0, 0.0, 0.0, 0.0, 0.0], 6194: [1.0, 0.0, 0.0, 0.0, 0.0], 3106: [1.0, 0.0, 0.0, 0.0, 0.0], 11093: [1.0, 0.0, 0.0, 0.0, 0.0], 24227: [1.0, 0.0, 0.0, 0.0, 0.0], 5129: [1.0, 0.0, 0.0, 0.0, 0.0], 2903: [1.0, 0.0, 0.0, 0.0, 0.0], 13130: [1.0, 0.0, 0.0, 0.0, 0.0], 20111: [1.0, 0.0, 0.0, 0.0, 0.0], 14717: [1.0, 0.0, 0.0, 0.0, 0.0], 5097: [1.0, 0.0, 0.0, 0.0, 0.0], 3573: [1.0, 0.0, 0.0, 0.0, 0.0], 6754: [1.0, 0.0, 0.0, 0.0, 0.0], 27854: [1.0, 0.0, 0.0, 0.0, 0.0], 11081: [1.0, 0.0, 0.0, 0.0, 0.0], 5436: [1.0, 0.0, 0.0, 0.0, 0.0], 30111: [1.0, 0.0, 0.0, 0.0, 0.0], 10904: [1.0, 0.0, 0.0, 0.0, 0.0], 4084: [1.0, 0.0, 0.0, 0.0, 0.0], 24143: [1.0, 0.0, 0.0, 0.0, 0.0], 17409: [1.0, 0.0, 0.0, 0.0, 0.0], 1033: [1.0, 0.0, 0.0, 0.0, 0.0], 6247: [1.0, 0.0, 0.0, 0.0, 0.0], 4651: [1.0, 0.0, 0.0, 0.0, 0.0], 10453: [1.0, 0.0, 0.0, 0.0, 0.0], 4029: [1.0, 0.0, 0.0, 0.0, 0.0], 24181: [1.0, 0.0, 0.0, 0.0, 0.0], 3589: [1.0, 0.0, 0.0, 0.0, 0.0], 11439: [1.0, 0.0, 0.0, 0.0, 0.0], 3401: [1.0, 0.0, 0.0, 0.0, 0.0], 20241: [1.0, 0.0, 0.0, 0.0, 0.0], 5467: [1.0, 0.0, 0.0, 0.0, 0.0], 8715: [1.0, 0.0, 0.0, 0.0, 0.0], 2505: [1.0, 0.0, 0.0, 0.0, 0.0], 4809: [1.0, 0.0, 0.0, 0.0, 0.0], 11887: [1.0, 0.0, 0.0, 0.0, 0.0], 3054: [1.0, 0.0, 0.0, 0.0, 0.0], 9658: [1.0, 0.0, 0.0, 0.0, 0.0], 1071: [1.0, 0.0, 0.0, 0.0, 0.0]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_list[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ly2VzRiUETA7",
        "outputId": "b7f4f698-4b46-4523-fa9b-0f9cbfc450f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(250, 688, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.special import softmax\n",
        "import numpy as np\n",
        "hardcoded_preds = []\n",
        "softmax_combined_test_preds_proba = softmax(combined_test_preds_proba,axis=-1)\n",
        "for i1, text in enumerate(tokenized_datasets_list[0][\"test\"][\"input_ids\"]):\n",
        "    sentence = []\n",
        "    for i2, id in enumerate(text):\n",
        "        if id in hardcoded_dict:\n",
        "            sentence.append(softmax_combined_test_preds_proba[i1][i2]*0 + np.array(hardcoded_dict[id])*1)\n",
        "        else:\n",
        "            sentence.append(softmax_combined_test_preds_proba[i1][i2])\n",
        "    for i in range(688-len(sentence)):\n",
        "      sentence.append([0.2,0.2,0.2,0.2,0.2])\n",
        "    hardcoded_preds.append(np.array(sentence))\n",
        "hardcoded_preds_np = np.array(hardcoded_preds)"
      ],
      "metadata": {
        "id": "pMffreruEBKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from deap import base, creator, tools, algorithms\n",
        "# Define the evaluation function\n",
        "def evaluate(individual):\n",
        "    x1, x2 = individual\n",
        "    # Replace this with your actual function\n",
        "    #coef_list = random_floats_summing_to_one(8).tolist()\n",
        "    coef_list = [x1,x2]\n",
        "    combined_test_preds_proba = prediction_list[0]*coef_list[0] + prediction_list[1]*coef_list[1]\n",
        "    test_labels = tokenized_datasets_list[1][\"test\"][\"labels\"]\n",
        "    result_f1 = compute_metrics2((combined_test_preds_proba,test_labels))[\"f1\"]\n",
        "    return (result_f1,)"
      ],
      "metadata": {
        "id": "SYTM4jzq0qUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize weights to sum to 1\n",
        "def normalize_weights(individual):\n",
        "    total = sum(individual)\n",
        "    return [x / total for x in individual]"
      ],
      "metadata": {
        "id": "FBu_2bQO00l9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the fitness and individual classes\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "# Initialize the toolbox\n",
        "toolbox = base.Toolbox()\n",
        "\n",
        "# Attribute generator with normalization\n",
        "toolbox.register(\"attr_float\", random.uniform, 0, 1)\n",
        "toolbox.register(\"individual\", tools.initIterate, creator.Individual,\n",
        "                 lambda: normalize_weights([random.uniform(0, 1) for _ in range(3)]))\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "# Register the evaluation function\n",
        "toolbox.register(\"evaluate\", evaluate)\n",
        "\n",
        "# Register the genetic operators\n",
        "toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
        "toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=0.1, indpb=0.2)\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)"
      ],
      "metadata": {
        "id": "gHiNV5_ZRNvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "from scipy.optimize import differential_evolution\n",
        "\n",
        "# Genetic Algorithm parameters\n",
        "population_size = 200\n",
        "generations = 20\n",
        "crossover_probability = 0.7\n",
        "mutation_probability = 0.2\n",
        "\n",
        "# Parallelization setup\n",
        "pool = multiprocessing.Pool()\n",
        "toolbox.register(\"map\", pool.map)\n",
        "\n",
        "# Create the initial population\n",
        "population = toolbox.population(n=population_size)\n",
        "\n",
        "# Apply the genetic algorithm\n",
        "algorithms.eaSimple(population, toolbox, cxpb=crossover_probability, mutpb=mutation_probability,\n",
        "                    ngen=generations, verbose=True)\n",
        "\n",
        "# Close the pool\n",
        "pool.close()\n",
        "pool.join()\n",
        "\n",
        "# Extract the best individual after the optimization\n",
        "best_individual = tools.selBest(population, k=1)[0]\n",
        "print('Best individual:', best_individual)\n",
        "print('Best fitness:', best_individual.fitness.values[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P07qvosIRR4l",
        "outputId": "d5ff7c46-d85e-414c-b70f-7bcdc1721a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ANAT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-PRESENT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-ABSENT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-UNCERTAIN seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ANAT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ANAT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-PRESENT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-PRESENT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ANAT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-ABSENT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-PRESENT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-ABSENT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-ABSENT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-UNCERTAIN seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ANAT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-PRESENT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-UNCERTAIN seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-UNCERTAIN seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ANAT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-PRESENT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-ABSENT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ANAT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-ABSENT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-PRESENT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ANAT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ANAT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-PRESENT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-PRESENT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-UNCERTAIN seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-ABSENT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-ABSENT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ANAT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-ABSENT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-UNCERTAIN seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-UNCERTAIN seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-UNCERTAIN seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-PRESENT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-ABSENT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ANAT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-PRESENT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-UNCERTAIN seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-UNCERTAIN seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-ABSENT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-UNCERTAIN seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ANAT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-PRESENT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-ABSENT seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: OBS-UNCERTAIN seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gen\tnevals\n",
            "0  \t200   \n",
            "1  \t146   \n",
            "2  \t143   \n",
            "3  \t154   \n",
            "4  \t158   \n",
            "5  \t164   \n",
            "6  \t157   \n",
            "7  \t152   \n",
            "8  \t148   \n",
            "9  \t168   \n",
            "10 \t153   \n",
            "11 \t136   \n",
            "12 \t166   \n",
            "13 \t163   \n",
            "14 \t159   \n",
            "15 \t136   \n",
            "16 \t158   \n",
            "17 \t156   \n",
            "18 \t140   \n",
            "19 \t168   \n",
            "20 \t147   \n",
            "Best individual: [0.45924524522676324, 0.40189315664805253, -0.02642922208540941]\n",
            "Best fitness: 0.8324135927969795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Differential Evolution for fine-tuning (optional)\n",
        "bounds = [(0, 1)] * 3  # Weights should be between 0 and 1\n",
        "\n",
        "def objective_function(x):\n",
        "    return -evaluate(normalize_weights(x))[0]  # scipy minimizes, so we negate the function\n",
        "\n",
        "maxf1 = 0.8549\n",
        "# Create an initial population for differential evolution\n",
        "init_list = tools.selBest(population,k=5)\n",
        "init_pop = [normalize_weights(ind) for ind in init_list]\n",
        "\n",
        "for i in range(5):\n",
        "  result = differential_evolution(objective_function, bounds, init=init_pop, maxiter=100000)\n",
        "  best_weights_de = normalize_weights(result.x)\n",
        "  print('Iteration', i+1)\n",
        "  print('Best individual after DE:', best_weights_de)\n",
        "  print('Best fitness after DE:', -result.fun)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YB6bXlPDTEfc",
        "outputId": "72440f7d-f7cb-483c-bece-00d90f3fd205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1\n",
            "Best individual after DE: [0.5295403599335491, 0.4627638040143092, 0.007695836052141608]\n",
            "Best fitness after DE: 0.8324135927969795\n",
            "Iteration 2\n",
            "Best individual after DE: [0.5297839243989018, 0.46308213179868585, 0.007133943802412323]\n",
            "Best fitness after DE: 0.8324135927969795\n",
            "Iteration 3\n",
            "Best individual after DE: [0.5297239926831792, 0.4629560445832274, 0.007319962733593366]\n",
            "Best fitness after DE: 0.8324135927969795\n",
            "Iteration 4\n",
            "Best individual after DE: [0.5296187995565257, 0.4628476738442687, 0.007533526599205672]\n",
            "Best fitness after DE: 0.8324135927969795\n",
            "Iteration 5\n",
            "Best individual after DE: [0.5295883638968771, 0.46281195968323785, 0.007599676419884995]\n",
            "Best fitness after DE: 0.8324135927969795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate([0.46,0.54])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hy5HLJmo02mT",
        "outputId": "0d8cc744-58c2-42dc-eba9-f2ba0b96467e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8903341897480656,)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(450,480):\n",
        "  value = i/1000.0\n",
        "  print(value,\" \",1-value,\" : \",evaluate([value,1-value]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlvdN36TY4hp",
        "outputId": "d74a9d68-16db-4ce3-948c-6c84d91a375c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.45   0.55  :  (0.890185784914241,)\n",
            "0.451   0.5489999999999999  :  (0.8902122350217551,)\n",
            "0.452   0.548  :  (0.890253891657866,)\n",
            "0.453   0.5469999999999999  :  (0.890266926156881,)\n",
            "0.454   0.546  :  (0.8902933614905151,)\n",
            "0.455   0.5449999999999999  :  (0.8902925787630583,)\n",
            "0.456   0.544  :  (0.8903067786619067,)\n",
            "0.457   0.5429999999999999  :  (0.890293702396991,)\n",
            "0.458   0.542  :  (0.8903076933769589,)\n",
            "0.459   0.5409999999999999  :  (0.8903076689217219,)\n",
            "0.46   0.54  :  (0.8903341897480656,)\n",
            "0.461   0.5389999999999999  :  (0.8903070596941025,)\n",
            "0.462   0.538  :  (0.8903070596941025,)\n",
            "0.463   0.5369999999999999  :  (0.8902931230916293,)\n",
            "0.464   0.536  :  (0.8902800466025412,)\n",
            "0.465   0.5349999999999999  :  (0.8902666863921135,)\n",
            "0.466   0.534  :  (0.8902539799482374,)\n",
            "0.467   0.5329999999999999  :  (0.890295610622329,)\n",
            "0.468   0.532  :  (0.8902965497333921,)\n",
            "0.469   0.531  :  (0.8902415500781761,)\n",
            "0.47   0.53  :  (0.8902135983818472,)\n",
            "0.471   0.529  :  (0.890240609792928,)\n",
            "0.472   0.528  :  (0.8902394853885547,)\n",
            "0.473   0.527  :  (0.8902394638014514,)\n",
            "0.474   0.526  :  (0.8902123117399308,)\n",
            "0.475   0.525  :  (0.8902255717316073,)\n",
            "0.476   0.524  :  (0.8902242238381584,)\n",
            "0.477   0.523  :  (0.8902652471187993,)\n",
            "0.478   0.522  :  (0.8902512291640476,)\n",
            "0.479   0.521  :  (0.8902382522917837,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coef_list = [0.529,0.471]\n",
        "combined_test_preds_proba = prediction_list[0]#*coef_list[0] + prediction_list[1]*coef_list[1]\n",
        "test_labels = tokenized_datasets_list[0][\"test\"][\"labels\"]\n",
        "print(compute_metrics2((combined_test_preds_proba,test_labels)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVxX2Pl0i6pi",
        "outputId": "222389f4-62cf-49cc-99a6-38f89b2aa2c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'precision': 0.8861702641954879, 'recall': 0.8855099849104825, 'f1': 0.8848582084053055, 'accuracy': 0.8855099849104825}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## google-t5/t5-large and google-t5/t5-base models ensemble\n",
        "\n",
        "coef_list = **[0.288, 0.712]**\n",
        "\n",
        "{'precision': 0.8128797083839611, 'recall': 0.8872679045092838, **'f1': 0.8484464172479391**, 'accuracy': 0.8938628987312723}"
      ],
      "metadata": {
        "id": "y4ZxIhbsizBH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## impression_yok modelleri ensemble\n",
        "\n",
        "coef_list = [0.529,0.471]\n",
        "\n",
        "{'precision': 0.7962243198223209, 'recall': 0.8717325227963526, 'f1': 0.8322692977365062, 'accuracy': 0.8906757656910591}\n"
      ],
      "metadata": {
        "id": "tcriB3I05lTM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### seqeval yok\n",
        "\n",
        "coef_list = [0.46,0.54]\n",
        "\n",
        "{'precision': 0.8913930899320432, 'recall': 0.8909748372099346, 'f1': 0.8903341897480656, 'accuracy': 0.8909748372099346}"
      ],
      "metadata": {
        "id": "1Apu3g-paxG7"
      }
    }
  ]
}