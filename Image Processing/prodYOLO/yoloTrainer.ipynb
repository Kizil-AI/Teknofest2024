{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.16 ðŸš€ Python-3.11.8 torch-2.2.1 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=prod.yaml, epochs=58, time=None, patience=100, batch=8, imgsz=1024, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=yolov8n_prod4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.4, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\yolov8n_prod4\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\alt_user\\Desktop\\prodYOLO\\prodAugmented\\train\\labels.cache... 7879 images, 3904 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7879/7879 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\alt_user\\Desktop\\prodYOLO\\prodAugmented\\test\\labels.cache... 1499 images, 763 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1499/1499 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\yolov8n_prod4\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 1024 train, 1024 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\yolov8n_prod4\u001b[0m\n",
      "Starting training for 58 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/58      2.69G      2.713      6.582      1.818         14       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:53<00:00,  5.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:16<00:00,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.464      0.224      0.206     0.0725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/58      2.55G        2.6      3.089      1.828         11       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:39<00:00,  6.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:14<00:00,  6.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.437      0.221      0.214     0.0622\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/58      2.56G      2.563      2.942      1.817         17       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:40<00:00,  6.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:15<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.523        0.2      0.226     0.0699\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/58      2.56G       2.53       2.82      1.793          2       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:46<00:00,  5.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:15<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.532      0.177      0.168     0.0554\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/58      2.56G      2.455      2.701      1.762         11       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:45<00:00,  5.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:15<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.619      0.141      0.161     0.0561\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/58       2.7G      2.434      2.597      1.722         10       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:45<00:00,  5.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:15<00:00,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.537      0.281      0.277     0.0942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/58      2.55G      2.417       2.61        1.7          7       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:45<00:00,  5.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:14<00:00,  6.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142       0.63      0.286      0.319       0.11\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/58      2.55G      2.376      2.516      1.696         10       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:41<00:00,  6.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:15<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.674      0.241      0.281      0.105\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/58      2.55G      2.371      2.527      1.693          5       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:49<00:00,  5.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:15<00:00,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.651      0.282      0.331      0.126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/58      2.55G      2.336      2.526      1.687          5       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:45<00:00,  5.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:15<00:00,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.697      0.274       0.33      0.128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/58      2.55G      2.325       2.49      1.651          6       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:46<00:00,  5.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:15<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142       0.58      0.341      0.359      0.138\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/58      2.56G      2.319      2.405      1.664          3       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:45<00:00,  5.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:15<00:00,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.572      0.314      0.346      0.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/58      2.55G      2.292       2.39       1.63          6       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:46<00:00,  5.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:15<00:00,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.628      0.319      0.355       0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/58      2.55G      2.282      2.368      1.642          6       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:47<00:00,  5.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:15<00:00,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.539      0.299      0.326      0.111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/58      2.55G      2.262      2.342      1.624          5       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:52<00:00,  5.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:15<00:00,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.631      0.361      0.397      0.158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/58      2.62G      2.237      2.338      1.606          6       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:46<00:00,  5.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:15<00:00,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.624      0.317      0.352       0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/58      2.55G      2.233      2.313      1.586         10       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:49<00:00,  5.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:15<00:00,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.634       0.28       0.31       0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/58      2.55G      2.219      2.269      1.593         12       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:46<00:00,  5.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:15<00:00,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.597      0.349      0.374      0.145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/58      2.55G      2.203      2.295      1.586          4       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:48<00:00,  5.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:17<00:00,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.662      0.346       0.39      0.151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/58      2.55G       2.19      2.252      1.577          6       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:55<00:00,  5.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:16<00:00,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.654       0.32      0.365       0.14\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/58      2.55G      2.174      2.227      1.571          5       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:54<00:00,  5.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:16<00:00,  5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.606      0.369      0.401      0.156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/58      2.55G      2.164      2.193      1.545         13       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:53<00:00,  5.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:15<00:00,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.618      0.373      0.412      0.167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/58      2.55G      2.152      2.183      1.547          9       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:56<00:00,  5.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:17<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.652      0.364      0.411       0.16\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/58      2.55G      2.164      2.198      1.563          8       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:57<00:00,  5.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:17<00:00,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.595      0.363      0.401      0.161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/58      2.55G      2.137      2.129      1.533         10       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:58<00:00,  5.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:17<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.595      0.366      0.392      0.154\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/58      2.55G      2.146      2.163      1.533          3       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:56<00:00,  5.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:16<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.675      0.379       0.44      0.169\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/58      2.55G      2.118      2.135      1.527          5       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:53<00:00,  5.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:14<00:00,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.639       0.35      0.397      0.152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/58      2.63G      2.121       2.13      1.526          6       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:39<00:00,  6.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:14<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142        0.6      0.373      0.419      0.165\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/58      2.55G      2.113       2.12      1.528         14       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:38<00:00,  6.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:14<00:00,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.626       0.39      0.441      0.173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/58      2.55G      2.092      2.108      1.521          8       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:38<00:00,  6.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:14<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.612      0.391      0.421      0.161\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/58      2.55G      2.095      2.093      1.505          9       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:38<00:00,  6.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:14<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.623      0.391      0.423       0.16\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/58      2.55G      2.108      2.092      1.515         16       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:38<00:00,  6.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:14<00:00,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.611      0.372       0.41      0.167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/58      2.55G      2.081      2.076      1.508          2       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:38<00:00,  6.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:14<00:00,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.658      0.396      0.436      0.173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/58      2.55G      2.065       2.04      1.497          5       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:38<00:00,  6.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:14<00:00,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.665       0.38      0.425       0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/58      2.55G       2.06      2.022      1.498          6       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:38<00:00,  6.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:14<00:00,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.636      0.405      0.437      0.169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/58      2.55G      2.049      2.013      1.487          4       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:38<00:00,  6.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:14<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142       0.62      0.394      0.437      0.173\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/58       2.7G      2.058       2.05      1.485         18       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:40<00:00,  6.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:14<00:00,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.667      0.397      0.446      0.172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/58      2.55G      2.029      2.038      1.476          7       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:47<00:00,  5.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:15<00:00,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.635      0.403      0.432      0.175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/58      2.63G       2.04          2      1.494          9       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:46<00:00,  5.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:15<00:00,  6.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142       0.66      0.403      0.447       0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/58      2.55G      2.004      1.928      1.464          8       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:47<00:00,  5.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:15<00:00,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.634      0.404      0.445      0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/58      2.55G      2.013      1.979      1.463          4       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:44<00:00,  5.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:14<00:00,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.644        0.4      0.446      0.175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/58      2.55G      1.989       1.93      1.444          9       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:40<00:00,  6.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:14<00:00,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.646      0.413      0.446      0.171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/58      2.55G      1.988      1.925      1.444          6       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:41<00:00,  6.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:15<00:00,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.655      0.408       0.45       0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/58      2.55G      1.984      1.914      1.457          6       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:45<00:00,  5.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:15<00:00,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.641      0.409      0.456      0.186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/58      2.55G      1.989      1.922      1.458          5       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:46<00:00,  5.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:16<00:00,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.654      0.414      0.457      0.182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/58      2.55G      1.965      1.892       1.44          3       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:45<00:00,  5.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:15<00:00,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142       0.66      0.415      0.452      0.181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/58      2.55G      1.955      1.884      1.446          8       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:52<00:00,  5.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:15<00:00,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.653      0.408      0.445      0.178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/58      2.55G      1.947      1.863       1.43         15       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:50<00:00,  5.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:16<00:00,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.653      0.415      0.453      0.182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/58      2.55G      1.931      1.842      1.452          3       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:29<00:00,  6.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:14<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.645      0.398      0.438      0.175\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/58      2.55G      1.916      1.833       1.44          5       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:34<00:00,  6.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:14<00:00,  6.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.699      0.394       0.45      0.183\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      51/58      2.55G      1.878      1.807      1.425         12       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:34<00:00,  6.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:14<00:00,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.659      0.416      0.454      0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      52/58      2.55G      1.878      1.779       1.43          6       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:40<00:00,  6.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:14<00:00,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142       0.65      0.418       0.46      0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      53/58      2.55G      1.856      1.775      1.409          5       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:41<00:00,  6.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:15<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.672      0.411       0.45      0.181\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      54/58      2.55G      1.871      1.777      1.411          7       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:41<00:00,  6.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:15<00:00,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.651      0.414      0.456      0.182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      55/58      2.55G       1.85      1.757      1.399          3       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:40<00:00,  6.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:15<00:00,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.621      0.417      0.449      0.182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      56/58      2.55G      1.846       1.74      1.402          5       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:42<00:00,  6.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:15<00:00,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.636      0.431       0.46      0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      57/58      2.55G      1.847      1.742      1.406          5       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:43<00:00,  6.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:15<00:00,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.636      0.428      0.453      0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      58/58      2.55G       1.84      1.735      1.395         11       1024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 985/985 [02:40<00:00,  6.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:15<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142       0.66      0.422      0.461      0.184\n",
      "\n",
      "58 epochs completed in 2.943 hours.\n",
      "Optimizer stripped from runs\\detect\\yolov8n_prod4\\weights\\last.pt, 6.3MB\n",
      "Optimizer stripped from runs\\detect\\yolov8n_prod4\\weights\\best.pt, 6.3MB\n",
      "\n",
      "Validating runs\\detect\\yolov8n_prod4\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.1.16 ðŸš€ Python-3.11.8 torch-2.2.1 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:14<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1499       1142      0.642      0.409      0.455      0.186\n",
      "Speed: 0.7ms preprocess, 3.1ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\yolov8n_prod4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolov8n.pt')\n",
    " \n",
    "# Training.\n",
    "results = model.train(\n",
    "   data='prod.yaml',\n",
    "   imgsz=1024,\n",
    "   epochs=58,\n",
    "   batch=8,\n",
    "   iou = 0.4,\n",
    "   warmup_bias_lr = 0.0,\n",
    "   name='yolov8n_prod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8x.pt to 'yolov8x.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131M/131M [00:03<00:00, 39.4MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x512 (no detections), 134.3ms\n",
      "Speed: 6.8ms preprocess, 134.3ms inference, 51.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 28.7ms\n",
      "Speed: 10.2ms preprocess, 28.7ms inference, 151.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 24.9ms\n",
      "Speed: 13.9ms preprocess, 24.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 29.7ms\n",
      "Speed: 3.6ms preprocess, 29.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 30.0ms\n",
      "Speed: 1.2ms preprocess, 30.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 (no detections), 35.3ms\n",
      "Speed: 0.0ms preprocess, 35.3ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 pizza, 29.7ms\n",
      "Speed: 10.1ms preprocess, 29.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 30.2ms\n",
      "Speed: 0.5ms preprocess, 30.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 29.5ms\n",
      "Speed: 2.5ms preprocess, 29.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 30.1ms\n",
      "Speed: 1.6ms preprocess, 30.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 30.3ms\n",
      "Speed: 1.6ms preprocess, 30.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 26.7ms\n",
      "Speed: 2.3ms preprocess, 26.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 28.4ms\n",
      "Speed: 4.3ms preprocess, 28.4ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 29.6ms\n",
      "Speed: 3.0ms preprocess, 29.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 29.1ms\n",
      "Speed: 2.6ms preprocess, 29.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 (no detections), 26.2ms\n",
      "Speed: 2.7ms preprocess, 26.2ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 bowl, 1 vase, 30.2ms\n",
      "Speed: 3.2ms preprocess, 30.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 28.8ms\n",
      "Speed: 0.0ms preprocess, 28.8ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 31.0ms\n",
      "Speed: 1.5ms preprocess, 31.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 apple, 33.7ms\n",
      "Speed: 0.0ms preprocess, 33.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 (no detections), 30.6ms\n",
      "Speed: 0.0ms preprocess, 30.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 (no detections), 29.9ms\n",
      "Speed: 9.8ms preprocess, 29.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 apple, 1 vase, 25.6ms\n",
      "Speed: 5.2ms preprocess, 25.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 33.9ms\n",
      "Speed: 0.0ms preprocess, 33.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 apple, 28.3ms\n",
      "Speed: 2.0ms preprocess, 28.3ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 31.7ms\n",
      "Speed: 0.0ms preprocess, 31.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 29.8ms\n",
      "Speed: 9.1ms preprocess, 29.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 (no detections), 30.0ms\n",
      "Speed: 2.1ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 (no detections), 30.0ms\n",
      "Speed: 0.0ms preprocess, 30.0ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 (no detections), 29.0ms\n",
      "Speed: 9.7ms preprocess, 29.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 apple, 29.2ms\n",
      "Speed: 10.0ms preprocess, 29.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 (no detections), 29.0ms\n",
      "Speed: 9.6ms preprocess, 29.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 apple, 1 vase, 25.2ms\n",
      "Speed: 2.9ms preprocess, 25.2ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x544 1 vase, 137.6ms\n",
      "Speed: 9.9ms preprocess, 137.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x512 (no detections), 32.1ms\n",
      "Speed: 6.1ms preprocess, 32.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 32.9ms\n",
      "Speed: 0.0ms preprocess, 32.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 apple, 24.8ms\n",
      "Speed: 1.5ms preprocess, 24.8ms inference, 7.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 27.3ms\n",
      "Speed: 0.8ms preprocess, 27.3ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x480 1 vase, 118.4ms\n",
      "Speed: 0.0ms preprocess, 118.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x512 1 vase, 36.6ms\n",
      "Speed: 0.0ms preprocess, 36.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x544 1 apple, 34.3ms\n",
      "Speed: 9.4ms preprocess, 34.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x512 1 vase, 31.0ms\n",
      "Speed: 1.9ms preprocess, 31.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 (no detections), 25.4ms\n",
      "Speed: 8.0ms preprocess, 25.4ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 (no detections), 29.8ms\n",
      "Speed: 7.1ms preprocess, 29.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 28.8ms\n",
      "Speed: 0.0ms preprocess, 28.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 27.7ms\n",
      "Speed: 9.1ms preprocess, 27.7ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 (no detections), 24.3ms\n",
      "Speed: 5.0ms preprocess, 24.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 apple, 1 vase, 25.1ms\n",
      "Speed: 5.5ms preprocess, 25.1ms inference, 7.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 31.7ms\n",
      "Speed: 0.0ms preprocess, 31.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 apple, 1 clock, 1 vase, 30.1ms\n",
      "Speed: 0.5ms preprocess, 30.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 31.9ms\n",
      "Speed: 0.0ms preprocess, 31.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 apple, 27.5ms\n",
      "Speed: 0.0ms preprocess, 27.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 29.4ms\n",
      "Speed: 5.1ms preprocess, 29.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 32.5ms\n",
      "Speed: 0.0ms preprocess, 32.5ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 apple, 29.2ms\n",
      "Speed: 5.6ms preprocess, 29.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 bowl, 1 pizza, 29.1ms\n",
      "Speed: 0.0ms preprocess, 29.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 apple, 29.6ms\n",
      "Speed: 1.9ms preprocess, 29.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 28.5ms\n",
      "Speed: 0.0ms preprocess, 28.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 apple, 1 vase, 28.5ms\n",
      "Speed: 0.0ms preprocess, 28.5ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 person, 39.3ms\n",
      "Speed: 0.0ms preprocess, 39.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 person, 1 vase, 38.4ms\n",
      "Speed: 3.0ms preprocess, 38.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 39.8ms\n",
      "Speed: 10.2ms preprocess, 39.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 bicycle, 1 chair, 1 vase, 44.6ms\n",
      "Speed: 0.0ms preprocess, 44.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 36.4ms\n",
      "Speed: 4.0ms preprocess, 36.4ms inference, 9.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 48.6ms\n",
      "Speed: 0.0ms preprocess, 48.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 elephant, 48.6ms\n",
      "Speed: 0.0ms preprocess, 48.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 50.4ms\n",
      "Speed: 0.0ms preprocess, 50.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x480 1 apple, 44.5ms\n",
      "Speed: 6.3ms preprocess, 44.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x512 1 apple, 1 vase, 52.0ms\n",
      "Speed: 0.0ms preprocess, 52.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 apple, 41.3ms\n",
      "Speed: 8.7ms preprocess, 41.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 47.8ms\n",
      "Speed: 0.0ms preprocess, 47.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 44.0ms\n",
      "Speed: 0.0ms preprocess, 44.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 41.2ms\n",
      "Speed: 9.1ms preprocess, 41.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 44.2ms\n",
      "Speed: 0.0ms preprocess, 44.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 39.7ms\n",
      "Speed: 1.1ms preprocess, 39.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 37.8ms\n",
      "Speed: 10.7ms preprocess, 37.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 apple, 39.2ms\n",
      "Speed: 5.7ms preprocess, 39.2ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 38.0ms\n",
      "Speed: 2.4ms preprocess, 38.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 apple, 43.7ms\n",
      "Speed: 4.4ms preprocess, 43.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 40.3ms\n",
      "Speed: 0.5ms preprocess, 40.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 apple, 42.2ms\n",
      "Speed: 0.0ms preprocess, 42.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 40.8ms\n",
      "Speed: 3.5ms preprocess, 40.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 (no detections), 34.8ms\n",
      "Speed: 5.3ms preprocess, 34.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 39.2ms\n",
      "Speed: 1.0ms preprocess, 39.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 apple, 1 vase, 36.4ms\n",
      "Speed: 3.9ms preprocess, 36.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 39.9ms\n",
      "Speed: 2.1ms preprocess, 39.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 40.0ms\n",
      "Speed: 2.5ms preprocess, 40.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 41.1ms\n",
      "Speed: 0.0ms preprocess, 41.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 38.1ms\n",
      "Speed: 2.1ms preprocess, 38.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 apple, 40.9ms\n",
      "Speed: 3.2ms preprocess, 40.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 42.2ms\n",
      "Speed: 7.1ms preprocess, 42.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 (no detections), 43.7ms\n",
      "Speed: 2.1ms preprocess, 43.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 apple, 1 vase, 45.5ms\n",
      "Speed: 2.0ms preprocess, 45.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 40.4ms\n",
      "Speed: 6.8ms preprocess, 40.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x544 1 apple, 49.5ms\n",
      "Speed: 2.7ms preprocess, 49.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x512 1 vase, 40.6ms\n",
      "Speed: 3.5ms preprocess, 40.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x480 (no detections), 40.3ms\n",
      "Speed: 0.0ms preprocess, 40.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x512 1 vase, 42.3ms\n",
      "Speed: 5.9ms preprocess, 42.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 apple, 1 vase, 38.5ms\n",
      "Speed: 2.7ms preprocess, 38.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 (no detections), 39.8ms\n",
      "Speed: 1.2ms preprocess, 39.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 40.2ms\n",
      "Speed: 6.8ms preprocess, 40.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 apple, 1 vase, 39.1ms\n",
      "Speed: 3.0ms preprocess, 39.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 40.1ms\n",
      "Speed: 3.0ms preprocess, 40.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x480 1 vase, 41.4ms\n",
      "Speed: 2.2ms preprocess, 41.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 vase, 39.7ms\n",
      "Speed: 7.8ms preprocess, 39.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x512 (no detections), 40.3ms\n",
      "Speed: 2.2ms preprocess, 40.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x480 1 apple, 40.1ms\n",
      "Speed: 3.9ms preprocess, 40.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x512 1 apple, 1 vase, 38.5ms\n",
      "Speed: 4.1ms preprocess, 38.5ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 38.1ms\n",
      "Speed: 2.1ms preprocess, 38.1ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 apple, 38.5ms\n",
      "Speed: 3.6ms preprocess, 38.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 apple, 38.7ms\n",
      "Speed: 3.2ms preprocess, 38.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 39.7ms\n",
      "Speed: 6.3ms preprocess, 39.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 38.3ms\n",
      "Speed: 2.2ms preprocess, 38.3ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 41.3ms\n",
      "Speed: 3.0ms preprocess, 41.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 (no detections), 43.4ms\n",
      "Speed: 0.0ms preprocess, 43.4ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 apple, 1 vase, 42.6ms\n",
      "Speed: 2.3ms preprocess, 42.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 36.0ms\n",
      "Speed: 3.5ms preprocess, 36.0ms inference, 7.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 apple, 1 vase, 41.2ms\n",
      "Speed: 4.0ms preprocess, 41.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 (no detections), 41.5ms\n",
      "Speed: 5.8ms preprocess, 41.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 (no detections), 41.7ms\n",
      "Speed: 0.0ms preprocess, 41.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x480 1 vase, 41.2ms\n",
      "Speed: 3.0ms preprocess, 41.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x512 1 vase, 38.1ms\n",
      "Speed: 2.4ms preprocess, 38.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 34.9ms\n",
      "Speed: 3.1ms preprocess, 34.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 34.9ms\n",
      "Speed: 7.6ms preprocess, 34.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 (no detections), 34.4ms\n",
      "Speed: 2.0ms preprocess, 34.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 (no detections), 35.1ms\n",
      "Speed: 1.9ms preprocess, 35.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 34.2ms\n",
      "Speed: 2.1ms preprocess, 34.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 bowl, 33.1ms\n",
      "Speed: 6.7ms preprocess, 33.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 30.6ms\n",
      "Speed: 5.1ms preprocess, 30.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 (no detections), 31.8ms\n",
      "Speed: 1.2ms preprocess, 31.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 (no detections), 33.1ms\n",
      "Speed: 0.0ms preprocess, 33.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 (no detections), 39.4ms\n",
      "Speed: 0.0ms preprocess, 39.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 apple, 35.8ms\n",
      "Speed: 0.0ms preprocess, 35.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 clock, 33.0ms\n",
      "Speed: 2.0ms preprocess, 33.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 29.6ms\n",
      "Speed: 2.0ms preprocess, 29.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 clock, 33.6ms\n",
      "Speed: 2.0ms preprocess, 33.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x480 1 vase, 36.7ms\n",
      "Speed: 0.0ms preprocess, 36.7ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x512 (no detections), 32.4ms\n",
      "Speed: 3.3ms preprocess, 32.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 32.6ms\n",
      "Speed: 2.8ms preprocess, 32.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 32.7ms\n",
      "Speed: 5.0ms preprocess, 32.7ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 37.4ms\n",
      "Speed: 4.3ms preprocess, 37.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 39.3ms\n",
      "Speed: 5.1ms preprocess, 39.3ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 42.9ms\n",
      "Speed: 2.0ms preprocess, 42.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 vase, 42.7ms\n",
      "Speed: 2.5ms preprocess, 42.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Perform inference on the image\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mpmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m found\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Parse and display results\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alt_user\\anaconda3\\envs\\Yoloenv\\Lib\\site-packages\\ultralytics\\engine\\model.py:430\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alt_user\\anaconda3\\envs\\Yoloenv\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:204\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[1;32mc:\\Users\\alt_user\\anaconda3\\envs\\Yoloenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 35\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alt_user\\anaconda3\\envs\\Yoloenv\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:282\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(im0s)\n\u001b[0;32m    281\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[1;32m--> 282\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprofilers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alt_user\\anaconda3\\envs\\Yoloenv\\Lib\\site-packages\\ultralytics\\utils\\ops.py:52\u001b[0m, in \u001b[0;36mProfile.__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mtype\u001b[39m, value, traceback):  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Stop timing.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart  \u001b[38;5;66;03m# delta-time\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt\n",
      "File \u001b[1;32mc:\\Users\\alt_user\\anaconda3\\envs\\Yoloenv\\Lib\\site-packages\\ultralytics\\utils\\ops.py:62\u001b[0m, in \u001b[0;36mProfile.time\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get current time.\"\"\"\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcuda:\n\u001b[1;32m---> 62\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Users\\alt_user\\anaconda3\\envs\\Yoloenv\\Lib\\site-packages\\torch\\cuda\\__init__.py:801\u001b[0m, in \u001b[0;36msynchronize\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    799\u001b[0m _lazy_init()\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(device):\n\u001b[1;32m--> 801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_synchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "# Load a pre-trained YOLOv8 model\n",
    "pmodel = YOLO('yolov8x.pt')  # 'yolov8n.pt' is the nano model, you can replace it with your model path\n",
    "\n",
    "# Load an image\n",
    "for file in os.listdir(\"data/test/images\"):\n",
    "    image_path = 'data/test/images/'+file\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Perform inference on the image\n",
    "    results = pmodel.predict(image)\n",
    "    found=False\n",
    "    # Parse and display results\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            found=True\n",
    "            x1, y1, x2, y2 = box.xyxy[0]  # Get the bounding box coordinates\n",
    "            confidence = box.conf      # Confidence score\n",
    "            class_id = box.cls         # Class ID\n",
    "\n",
    "            # Draw the bounding box and label on the image\n",
    "            # label = f'{pmodel.names[class_id]} {confidence:.2f}'\n",
    "            cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            cv2.putText(image, \"cancer\", (int(x1), int(y1)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Save the output image\n",
    "    if(found):\n",
    "        output_path = f'predTest/{file[:-4]}.jpg'\n",
    "        cv2.imwrite(output_path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    for box in result.boxes:\n",
    "        print(\"a\")\n",
    "        break\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yoloenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
