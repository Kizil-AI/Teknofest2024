{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metin = \"\"\"\n",
    "Memeler ACR tip C heterojen yoğun paternde olup mamografik duyarlılık azalmıştır.\n",
    "Sağ meme; CC grafi santral kesimde milimetrik nodüler fokal asimetrik dansite izlendi. Farklı kadranlarda konturları fibroglandüler parankimle örtülü izodens nodüler lezyonlar mevcuttur. Sınırları seçilebilen kitle lezyonu, kalsifikasyon, yapısal bozulma saptanmamıştır.\n",
    "Sağ aksillada incelenen kesimde patolojik boyut ve görünümde büyümüş lenf nodu yoktur.\n",
    "Sol memede; alt iç kadranda irregüler şekilli konturu düzensiz olarak izlenen 1 1 mm boyutunda nodüler kitlesel lezyon izlendi. Tüm kadranlarda konturları fibroglandüler parankimle örtülü nodüler şüpheli lezyonlar mevcuttur. Sol aksillada incelenen kesimde patolojik boyut ve görünümde büyümüş lenf nodu yoktur.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Memeler', 'ACR', 'tip', 'heterojen', 'yoğun', 'paternde', 'olup', 'mamografik', 'duyarlılık', 'azalmıştır', 'Sağ', 'meme', 'grafi', 'santral', 'kesimde', 'milimetrik', 'nodüler', 'fokal', 'asimetrik', 'dansite', 'izlendi', 'Farklı', 'kadranlarda', 'konturları', 'fibroglandüler', 'parankimle', 'örtülü', 'izodens', 'nodüler', 'lezyonlar', 'mevcuttur', 'Sınırları', 'seçilebilen', 'kitle', 'lezyonu', 'kalsifikasyon', 'yapısal', 'bozulma', 'saptanmamıştır', 'Sağ', 'aksillada', 'incelenen', 'kesimde', 'patolojik', 'boyut', 've', 'görünümde', 'büyümüş', 'lenf', 'nodu', 'yoktur', 'Sol', 'memede', 'alt', 'iç', 'kadranda', 'irregüler', 'şekilli', 'konturu', 'düzensiz', 'olarak', 'izlenen', 'boyutunda', 'nodüler', 'kitlesel', 'lezyon', 'izlendi', 'Tüm', 'kadranlarda', 'konturları', 'fibroglandüler', 'parankimle', 'örtülü', 'nodüler', 'şüpheli', 'lezyonlar', 'mevcuttur', 'Sol', 'aksillada', 'incelenen', 'kesimde', 'patolojik', 'boyut', 've', 'görünümde', 'büyümüş', 'lenf', 'nodu', 'yoktur']\n"
     ]
    }
   ],
   "source": [
    "from trnlp.tokenization import TrnlpToken\n",
    "\n",
    "obj = TrnlpToken()\n",
    "obj.settext(metin)\n",
    "print(obj.wordtoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Memeler', 'ACR', 'tip', 'C', 'heterojen', 'yoğun', 'paternde', 'olup', 'mamografik', 'duyarlılık', 'azalmıştır', 'Sağ', 'meme', 'CC', 'grafi', 'santral', 'kesimde', 'milimetrik', 'nodüler', 'fokal', 'asimetrik', 'dansite', 'izlendi', 'Farklı', 'kadranlarda', 'konturları', 'fibroglandüler', 'parankimle', 'örtülü', 'izodens', 'nodüler', 'lezyonlar', 'mevcuttur', 'Sınırları', 'seçilebilen', 'kitle', 'lezyonu', 'kalsifikasyon', 'yapısal', 'bozulma', 'saptanmamıştır', 'Sağ', 'aksillada', 'incelenen', 'kesimde', 'patolojik', 'boyut', 've', 'görünümde', 'büyümüş', 'lenf', 'nodu', 'yoktur', 'Sol', 'memede', 'alt', 'iç', 'kadranda', 'irregüler', 'şekilli', 'konturu', 'düzensiz', 'olarak', 'izlenen', '1', '1', 'mm', 'boyutunda', 'nodüler', 'kitlesel', 'lezyon', 'izlendi', 'Tüm', 'kadranlarda', 'konturları', 'fibroglandüler', 'parankimle', 'örtülü', 'nodüler', 'şüpheli', 'lezyonlar', 'mevcuttur', 'Sol', 'aksillada', 'incelenen', 'kesimde', 'patolojik', 'boyut', 've', 'görünümde', 'büyümüş', 'lenf', 'nodu', 'yoktur']\n"
     ]
    }
   ],
   "source": [
    "import trnlp.tokenization\n",
    "print(trnlp.tokenization.word_token(metin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### trnlp.tokenization.TrnlpToken objesi oluşturup öyle metnin wordtoken larını bastırınca nedense CC kelimesi kayboluyor pek anlamadım ama stopword fln sayıyor galiba bilmiyorum. Onun yerine trnlp.tokenization.word_token() metodu daha iyi çalışıyor gibi en azından CC kaybolmuyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "156fbb2444b9428ea699b64f941c72c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at savasy/bert-base-turkish-ner-cased were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29f8a0b54fa5432eba0b999fe35acfce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/40.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25806614bf044d8db65bbef1f902d234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/251k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df178a1018de4f8f86c7c43285777b9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-PER',\n",
       "  'score': 0.99385166,\n",
       "  'index': 1,\n",
       "  'word': 'Mustafa',\n",
       "  'start': 0,\n",
       "  'end': 7},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9881671,\n",
       "  'index': 2,\n",
       "  'word': 'Kemal',\n",
       "  'start': 8,\n",
       "  'end': 13},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9957979,\n",
       "  'index': 3,\n",
       "  'word': 'Atatürk',\n",
       "  'start': 14,\n",
       "  'end': 21},\n",
       " {'entity': 'B-LOC',\n",
       "  'score': 0.90599865,\n",
       "  'index': 9,\n",
       "  'word': 'Samsun',\n",
       "  'start': 39,\n",
       "  'end': 45}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"savasy/bert-base-turkish-ner-cased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"savasy/bert-base-turkish-ner-cased\")\n",
    "ner=pipeline('ner', model=model, tokenizer=tokenizer)\n",
    "ner(\"Mustafa Kemal Atatürk 19 Mayıs 1919'da Samsun'a ayak bastı.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Yukarıdaki kod türkçe BERT in NER için özelleşmiş bir versiyonu, bunu ve başka türkçe BERT versiyonlarını denemem lazım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd695dfa96646b8a9266c8fc45a56e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d0ed1d288d412da2a7f216451147ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05fff875815e49f0a100f5969ada1035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c0a583362a4bf884c20a64c1d66913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/251k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'entity': 'LABEL_1',\n",
       "  'score': 0.66534454,\n",
       "  'index': 1,\n",
       "  'word': 'Mustafa',\n",
       "  'start': 0,\n",
       "  'end': 7},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.5862775,\n",
       "  'index': 2,\n",
       "  'word': 'Kemal',\n",
       "  'start': 8,\n",
       "  'end': 13},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.5838471,\n",
       "  'index': 3,\n",
       "  'word': 'Atatürk',\n",
       "  'start': 14,\n",
       "  'end': 21},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.565077,\n",
       "  'index': 4,\n",
       "  'word': '19',\n",
       "  'start': 22,\n",
       "  'end': 24},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.523689,\n",
       "  'index': 5,\n",
       "  'word': 'Mayıs',\n",
       "  'start': 25,\n",
       "  'end': 30},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.55996966,\n",
       "  'index': 6,\n",
       "  'word': '1919',\n",
       "  'start': 31,\n",
       "  'end': 35},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.6322437,\n",
       "  'index': 7,\n",
       "  'word': \"'\",\n",
       "  'start': 35,\n",
       "  'end': 36},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.66475874,\n",
       "  'index': 8,\n",
       "  'word': 'da',\n",
       "  'start': 36,\n",
       "  'end': 38},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.6942795,\n",
       "  'index': 9,\n",
       "  'word': 'Samsun',\n",
       "  'start': 39,\n",
       "  'end': 45},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.6886977,\n",
       "  'index': 10,\n",
       "  'word': \"'\",\n",
       "  'start': 45,\n",
       "  'end': 46},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.6450589,\n",
       "  'index': 11,\n",
       "  'word': 'a',\n",
       "  'start': 46,\n",
       "  'end': 47},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.52082604,\n",
       "  'index': 12,\n",
       "  'word': 'ayak',\n",
       "  'start': 48,\n",
       "  'end': 52},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.664959,\n",
       "  'index': 13,\n",
       "  'word': 'bastı',\n",
       "  'start': 53,\n",
       "  'end': 58},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.51083064,\n",
       "  'index': 14,\n",
       "  'word': '.',\n",
       "  'start': 58,\n",
       "  'end': 59}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-base-turkish-cased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\")\n",
    "ner=pipeline('ner', model=model, tokenizer=tokenizer)\n",
    "ner(\"Mustafa Kemal Atatürk 19 Mayıs 1919'da Samsun'a ayak bastı.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Yukarıdaki dbmdz/bert-base-turkish-cased modeli ner için özelleşmemiş dolayısıyla direkt olarak bir ner yaptırmaya çalıştırdığımda çalışmıyo, ama bu durum sadece bi üstteki savasy/bert-base-turkish-ner-cased modelini kullanmamız gerektiğini göstermez. Bunu da teknofestten gelen medikal raporlarla fine-tune ederek denememiz lazım, diğerinden daha bile iyi olabilir belki belli olmaz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trelloya yazdım buraya da yazıyım, normalde bir de loodos adında birinin de bir türkçe bert modeli vardı ama o uncased di ve uncasedde I ve İ sıkıntı çıkarıyo çünkü hepsini lowercase yapıyo python. Dolayısıyla onu test etmiyorum bile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ugrozkr/bert-base-turkish-uncased-finetuned-ner huggingface modeli şu dbmdz veya savasy ninkinden daha iyi olabilir hem NER için özellşemiş hemde yaptığı NER sadece standart NER (PER,LOC,ORG vs.) değil, başka entity kategorileri de var. Ayrıca zaten bu model de dmdbz ninkinden fine-tune edilmiş aynı savasy deki gibi."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
